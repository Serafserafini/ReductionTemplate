{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_csp import managetemp as mte\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from template_csp.distances import dist1, dist2, dist3, levensthein_distance\n",
    "import json\n",
    "\n",
    "hyperparameters = { \n",
    "    \"weight_occurrence\" : 1,\n",
    "    \"weight_sg\" : 0.001,\n",
    "    \"weight_formation_entalphy\" : 1,\n",
    "    \"n_final_templates\" : 20,\n",
    "    \"comp\" : 1,\n",
    "}\n",
    "\n",
    "ntemp_initial_set = 20\n",
    "\n",
    "with open(f'ENTHAPY/A{hyperparameters[\"comp\"]}B.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "test_elements=['Be', 'B', 'N', 'Mg', 'O', 'Li', 'C', 'Na', 'Si', 'S', 'Cl', 'F', 'P', 'H', 'Al']\n",
    "\n",
    "initial_set = mte.InitialSet(test_elements, hyperparameters, f'RunOneTempPerPair/{hyperparameters[\"comp\"]}/{ntemp_initial_set}/TemplateSet_0')\n",
    "final_set = mte.FinalSet(initial_set, test_elements, hyperparameters, f'RunOneTempPerPair/{hyperparameters[\"comp\"]}/{ntemp_initial_set}/PairSet_0')\n",
    "reduced_set = final_set.reduced_set()\n",
    "n_temp_final = final_set.num_final_template\n",
    "\n",
    "pmatrix = {}\n",
    "couples = np.array([])\n",
    "\n",
    "for i in range(len(test_elements)):\n",
    "    for j in range(i+1,len(test_elements)):\n",
    "        couple = [test_elements[i],test_elements[j]]\n",
    "        couple.sort()\n",
    "        couple = ''.join(couple)\n",
    "        pvec = np.zeros((2, len(subset_templates)))\n",
    "\n",
    "        for idx, template in enumerate(subset_templates):\n",
    "            pvec[0,idx] = df.loc[couple,template]\n",
    "            pvec[1,idx] = idx\n",
    "        \n",
    "        sorted_idx = np.argsort(pvec[0])\n",
    "        pvec[0] = pvec[0][sorted_idx]\n",
    "        pvec[1] = pvec[1][sorted_idx]\n",
    "\n",
    "        pmatrix[couple] = pvec\n",
    "        couples = np.append(couples, couple)\n",
    "\n",
    "lev_dist_matrix = np.zeros((len(couples), len(couples)))\n",
    "\n",
    "for row, couple1 in enumerate(couples):\n",
    "    for col, couple2 in enumerate(couples):\n",
    "        if row == col:\n",
    "            lev_dist_matrix[row,col] = 0\n",
    "        else:\n",
    "            lev_dist_matrix[row,col] = dist2(pmatrix[couple1], pmatrix[couple2]) \n",
    "print(len(subset_templates))\n",
    "print(lev_dist_matrix.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CLUSTER BY GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_csp import managetemp as mte\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from template_csp.distances import dist1, dist2, dist3\n",
    "import re\n",
    "\n",
    "hyperparameters = { \n",
    "    \"weight_occurrence\" : 1,\n",
    "    \"weight_sg\" : 0.001,\n",
    "    \"weight_formation_entalphy\" : 1,\n",
    "    \"lev_red\" : 0.9,\n",
    "}\n",
    "comp = 1\n",
    "df = pd.read_csv(f'A{comp}B/relaxation/RELAX_DATA', sep=\",\", index_col=0, na_filter = False)\n",
    "df_entforma = pd.read_csv(f'A{comp}B/relaxation/OneElementEnt.txt', sep=\",\", index_col=0, na_filter = False, header=None)\n",
    "test_elements=['Be', 'B', 'N', 'Mg', 'O', 'Li', 'C', 'Na', 'Si', 'S', 'Cl', 'F', 'P', 'H', 'Al']\n",
    "\n",
    "template_set = mte.TemplateSet(test_elements, 'RANDOM/FULL50sets/20/TemplateSet_3')\n",
    "pairset = mte.PairSet(template_set, test_elements, dist_function=levensthein_distance, relaxed_pairs='RANDOM/FULL50sets/20/PairSet_3', )\n",
    "reducted_set = pairset.reduced_set(hyperparameters)\n",
    "\n",
    "subset_templates = [f'{template_set.couples[i][0][0]}{template_set.couples[i][0][1]}_{template_set.couples[i][1]}' for i in reducted_set]\n",
    "n_temp_test = len(subset_templates)\n",
    "print(len(subset_templates))\n",
    "gs_temp = {}\n",
    "couples = np.array([])\n",
    "\n",
    "for i in range(len(test_elements)):\n",
    "    for j in range(i+1,len(test_elements)):\n",
    "        couple = [test_elements[i],test_elements[j]]\n",
    "        couple.sort()\n",
    "        couple = ''.join(couple)\n",
    "        pvec = np.zeros((2, len(subset_templates)))\n",
    "\n",
    "        for idx, template in enumerate(subset_templates):\n",
    "            pvec[0,idx] = df.loc[couple,template]\n",
    "            pvec[1,idx] = idx\n",
    "        \n",
    "        sorted_idx = np.argsort(pvec[0])\n",
    "        pvec[0] = pvec[0][sorted_idx]\n",
    "        pvec[1] = pvec[1][sorted_idx]\n",
    "\n",
    "        gs_temp[couple] = subset_templates[int(pvec[1][0])]\n",
    "        couples = np.append(couples, couple)\n",
    "\n",
    "pmatrix = {}\n",
    "for template in subset_templates:\n",
    "    pvec = np.zeros((2, len(couples)))\n",
    "    for idx, couple in enumerate(pairset.couples):\n",
    "        A = couple[0]#re.findall(r'[A-Z][a-z]*', couple)[0]\n",
    "        B = couple[1]#re.findall(r'[A-Z][a-z]*', couple)[1]\n",
    "        ent_form = (df_entforma.loc[A,1] + df_entforma.loc[B,1])/2\n",
    "        pvec[0,idx] = df.loc[A+B,template] - ent_form\n",
    "        pvec[1,idx] = idx\n",
    "    pmatrix[template] = pvec\n",
    "\n",
    "lev_dist_matrix = np.zeros((len(couples), len(couples)))\n",
    "for couple in couples:\n",
    "    for couple2 in couples:\n",
    "        row = np.where(couples == couple)[0][0]\n",
    "        col = np.where(couples == couple2)[0][0]\n",
    "        lev_dist_matrix[row, col] = dist2(pmatrix[gs_temp[couple]], pmatrix[gs_temp[couple2]])\n",
    " \n",
    "np.savetxt('CLUSTERS/ClustersDict/DistMatrix', lev_dist_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_temp['HLi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENDOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(11, 8))\n",
    "\n",
    "condensed_dist_matrix = squareform(lev_dist_matrix)\n",
    "Z = linkage(condensed_dist_matrix, method='average')\n",
    "\n",
    "num_clusters = 8\n",
    "cluster_labels = fcluster(Z, t=num_clusters, criterion='maxclust')\n",
    "threshold = Z[-(num_clusters-1), 2]\n",
    "\n",
    "dendro = dendrogram(Z ,labels = couples, leaf_rotation=90, leaf_font_size=5, ax=ax1, color_threshold=threshold)\n",
    "\n",
    "\n",
    "\n",
    "sorted_idx = dendro['leaves']\n",
    "\n",
    "new = lev_dist_matrix[sorted_idx, :][:, sorted_idx]\n",
    "cluster_labels_sorted = cluster_labels[sorted_idx]\n",
    "\n",
    "im = ax.imshow(new, cmap='Spectral') #or Spectral\n",
    "\n",
    "couples_in_clusters = []\n",
    "cluster_distances = {}\n",
    "\n",
    "unique_clusters = np.unique(cluster_labels_sorted)\n",
    "for cluster in unique_clusters:\n",
    "    # Trova gli indici che appartengono a questo cluster\n",
    "    cluster_indices = np.where(cluster_labels_sorted == cluster)[0]\n",
    "\n",
    "    pairwise_indices = [(i, j) for i in cluster_indices for j in cluster_indices if i < j]\n",
    "    # Calcola la distanza media per il cluster\n",
    "    distances = [new[i, j] for i, j in pairwise_indices]\n",
    "    mean_distance = np.mean(distances) if distances else 0  # Evita errori con cluster singoli\n",
    "    cluster_distances[cluster] = mean_distance\n",
    "\n",
    "\n",
    "    if len(cluster_indices) > 0:\n",
    "        # Trova il primo e l'ultimo elemento del cluster per i bordi\n",
    "        start, end = cluster_indices[0], cluster_indices[-1]\n",
    "        cluster_size = end - start + 1\n",
    "        couples_in_clusters.append(np.array(couples)[sorted_idx][start:end+1])\n",
    "\n",
    "        # Aggiungi un rettangolo per evidenziare il cluster con un piccolo offset\n",
    "        rect = patches.Rectangle((start - 0.5, start - 0.5), cluster_size, cluster_size,\n",
    "                                 linewidth=3, edgecolor='black', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# Imposta i tick e mostra la figura\n",
    "ax.set_xticks(np.arange(len(couples)))\n",
    "ax.set_yticks(np.arange(len(couples)))\n",
    "ax.set_xticklabels(np.array(couples)[sorted_idx], fontsize=5, rotation=90)\n",
    "ax.set_yticklabels(np.array(couples)[sorted_idx], fontsize=5)  \n",
    "ax.set_xlabel('Couples', fontsize=15)\n",
    "ax.set_ylabel('Couples', fontsize=15)\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax, orientation=\"vertical\", fraction=0.046, pad=0.04, label='Levenshtein distance')\n",
    "cbar.ax.yaxis.label.set_size(15)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "cbar.ax.yaxis.set_label_coords(+2.5, 0.5)\n",
    "\n",
    "fig.savefig('MatrixHeatmap.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "ax1.axhline(y=threshold-0.005, color='r', linestyle='--')\n",
    "ax1.set_ylabel('Levenshtein distance', fontsize=20)\n",
    "ax1.set_xlabel('Couples', fontsize=20)\n",
    "ax1.xaxis.set_label_coords(0.5, -0.18)\n",
    "ax1.yaxis.set_label_coords(-0.07, 0.5)\n",
    "yticks = np.linspace(0, 0.5, 5)   \n",
    "yticks = np.round(yticks, decimals=1)\n",
    "ax1.set_yticks(yticks)\n",
    "ax1.set_yticklabels(yticks, fontsize=10)\n",
    "ax1.grid(True, ls=':', axis='y')\n",
    "plt.show()\n",
    "fig1.savefig('../LaTeX/Figure Risultati/Dendrogram.png', bbox_inches='tight')\n",
    "\n",
    "print(cluster_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in couples_in_clusters:\n",
    "    for i in cluster:\n",
    "        print(i+',', end=' ')\n",
    "    print('\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIE CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "total_hist = {}\n",
    "hist = {}\n",
    "len_cluster = []\n",
    "for idx_cluster, cluster in enumerate(couples_in_clusters):\n",
    "    if len(cluster) == 1:\n",
    "        continue\n",
    "    hist[f'{idx_cluster}'] = {}\n",
    "    len_cluster.append(len(cluster))\n",
    "    for i in cluster:\n",
    "        sg = subset_templates[int(pmatrix[i][1][0])]\n",
    "\n",
    "        if sg not in hist[f'{idx_cluster}'].keys():\n",
    "            hist[f'{idx_cluster}'][sg] = 1/len(cluster)\n",
    "        else:\n",
    "            hist[f'{idx_cluster}'][sg] +=1/len(cluster)\n",
    "            \n",
    "        if sg not in total_hist.keys():\n",
    "            total_hist[sg] = 1\n",
    "        else:\n",
    "            total_hist[sg] +=1\n",
    "            \n",
    "colormap = {}\n",
    "for idx, template in enumerate(total_hist.keys()):\n",
    "    colormap[f'{template}'] = cm.Set2(idx/len(total_hist.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Configura il layout per una pagina A4 in orizzontale\n",
    "fig, axes = plt.subplots(4, 2, figsize=(8.3, 11.7))  # 4 righe, 2 colonne\n",
    "axes = axes.flatten()  # Converti in un array monodimensionale per iterare facilmente\n",
    "\n",
    "# Itera attraverso i grafici e le assi\n",
    "for idx_cluster, (histcluster, ax) in enumerate(zip(hist.values(), axes)):\n",
    "    title_text = f'Cluster {idx_cluster+1}\\n{len_cluster[idx_cluster]} pairs\\nAvg: {cluster_distances[idx_cluster+1]:.2f}'\n",
    "\n",
    "    labels = list(histcluster.keys())\n",
    "    values = list(histcluster.values())\n",
    "    colors = [colormap[f'{i}'] for i in labels]\n",
    "    labels = [f'{x.split(\"_\")[0]} {x.split(\"_\")[1]}' for x in labels]\n",
    "\n",
    "    # Disegna il donut chart senza percentuali\n",
    "    wedges, texts = ax.pie(\n",
    "        values, labels=None, colors=colors,  # Disabilita i label automatici\n",
    "        wedgeprops=dict(edgecolor='black', linewidth=1.5), startangle=0\n",
    "    )\n",
    "\n",
    "    # Aggiungi il buco al centro con il bordo nero\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white', edgecolor='black', linewidth=1.5)\n",
    "    ax.add_artist(centre_circle)\n",
    "\n",
    "    # Aggiungi il titolo al centro del buco\n",
    "    ax.text(\n",
    "        0, 0, title_text, ha='center', va='center', fontsize=10,\n",
    "        fontweight='bold', color='black'\n",
    "    )\n",
    "\n",
    "    # Aggiungi manualmente label e percentuali centrati\n",
    "    for wedge, value, label in zip(wedges, values, labels):\n",
    "        # Calcola l'angolo medio della fetta\n",
    "        angle = (wedge.theta2 + wedge.theta1) / 2\n",
    "        x = np.cos(np.radians(angle)) * 1.3  # Posizione leggermente fuori dalla fetta\n",
    "        y = np.sin(np.radians(angle)) * 1.3\n",
    "\n",
    "        # Posiziona il label\n",
    "        ax.text(\n",
    "            x, y, label, ha='center', va='center', fontsize=8,\n",
    "            fontweight='bold', color='black'\n",
    "        )\n",
    "\n",
    "        # Posiziona la percentuale sotto il label\n",
    "        percentage = f\"{value * 100:.1f}%\"\n",
    "        ax.text(\n",
    "            x, y - 0.13, percentage, ha='center', va='center', fontsize=8,\n",
    "            color='black'\n",
    "        )\n",
    "\n",
    "    ax.axis('equal')  # Mantieni l'aspetto circolare\n",
    "\n",
    "# Rimuovi assi inutilizzati (se ci sono meno grafici degli spazi disponibili)\n",
    "for ax in axes[len(hist):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Regola il layout per evitare sovrapposizioni\n",
    "plt.tight_layout()\n",
    "\n",
    "# Salva o mostra l'immagine finale\n",
    "plt.savefig(\"PieCharts.png\", dpi=300, bbox_inches='tight')  # Salva il file\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER PIE CHARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(15, 10))\n",
    "fig.suptitle(f'Total distribution', fontsize=20, fontweight='bold', y=0.95)\n",
    "\n",
    "ax.bar(total_hist.keys(), total_hist.values(),  color='blue', edgecolor='black', linewidth=1.2)\n",
    "ax.set_xlabel('Template', fontsize=15)\n",
    "ax.set_ylabel('Occurrence', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "total_hist = {}\n",
    "hist = {}\n",
    "len_cluster = []\n",
    "for idx_cluster, cluster in enumerate(couples_in_clusters):\n",
    "    if len(cluster) == 1:\n",
    "        continue\n",
    "    hist[f'{idx_cluster}'] = {}\n",
    "    len_cluster.append(len(cluster))\n",
    "    for i in cluster:\n",
    "        sg = subset_templates[int(pmatrix[i][1][0])].split('_')[1]\n",
    "\n",
    "        if sg not in hist[f'{idx_cluster}'].keys():\n",
    "            hist[f'{idx_cluster}'][sg] = 1/len(cluster)\n",
    "        else:\n",
    "            hist[f'{idx_cluster}'][sg] +=1/len(cluster)\n",
    "            \n",
    "        if sg not in total_hist.keys():\n",
    "            total_hist[sg] = 1/len(cluster)\n",
    "        else:\n",
    "            total_hist[sg] +=1/len(cluster)\n",
    "            \n",
    "colormap = {}\n",
    "for idx, template in enumerate(total_hist.keys()):\n",
    "    colormap[f'{template}'] = cm.Set2(idx/len(total_hist.keys()))\n",
    "\n",
    "for idx_cluster, histcluster in enumerate(hist.values()):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(15, 10))\n",
    "    fig.suptitle(f'Cluster {idx_cluster} with {len_cluster[idx_cluster]} pairs', fontsize=20, fontweight='bold')\n",
    "    colors = [colormap[f'{int(i)}'] for i in histcluster.keys()]\n",
    "    wedges, texts, autotexts = ax.pie(histcluster.values(), autopct='%1.1f%%' ,labels = histcluster.keys(), colors = colors, wedgeprops=dict(edgecolor='black', linewidth=1.5), startangle=0)\n",
    "    ax.axis('equal')\n",
    "    # Personalizzazione del testo\n",
    "    for text in texts:\n",
    "        text.set_fontsize(20)  # Dimensione dei label\n",
    "        text.set_color('black')\n",
    "        text.set_fontweight('bold')  # Colore dei label\n",
    "\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(15)  # Dimensione delle percentuali\n",
    "        autotext.set_color('black')  # Colore delle percentuali\n",
    "        autotext.set_weight('bold')  # Grassetto per le percentuali\n",
    "    plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "total_hist = {}\n",
    "hist = {}\n",
    "len_cluster = []\n",
    "for idx_cluster, cluster in enumerate(couples_in_clusters):\n",
    "    if len(cluster) == 1:\n",
    "        continue\n",
    "    hist[f'{idx_cluster}'] = {}\n",
    "    len_cluster.append(len(cluster))\n",
    "    for i in cluster:\n",
    "        templist = f'{subset_templates[int(pmatrix[i][1][0])]},{subset_templates[int(pmatrix[i][1][1])]}'\n",
    "\n",
    "        flag = False\n",
    "        for key in hist[f'{idx_cluster}'].keys():\n",
    "            if set(templist.split(',')) == set(key.split(',')):\n",
    "                hist[f'{idx_cluster}'][key] +=1/len(cluster)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            hist[f'{idx_cluster}'][templist] = 1/len(cluster)\n",
    "            \n",
    "\n",
    "for idx, histcluster in enumerate(hist.values()):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(15, 10))\n",
    "    fig.suptitle(f'Cluster {idx_cluster} with {len_cluster[idx]} pairs', fontsize=20, fontweight='bold')\n",
    "    wedges, texts, autotexts = ax.pie(histcluster.values(), autopct='%1.1f%%' ,labels = histcluster.keys(), wedgeprops=dict(edgecolor='black', linewidth=1.5), startangle=0)\n",
    "    ax.axis('equal')\n",
    "    # Personalizzazione del testo\n",
    "    for text in texts:\n",
    "        text.set_fontsize(20)  # Dimensione dei label\n",
    "        text.set_color('black')\n",
    "        text.set_fontweight('bold')  # Colore dei label\n",
    "\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(15)  # Dimensione delle percentuali\n",
    "        autotext.set_color('black')  # Colore delle percentuali\n",
    "        autotext.set_weight('bold')  # Grassetto per le percentuali\n",
    "    plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PESO PRIMA COMPONENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "y1 = []\n",
    "y2 = []\n",
    "x = []\n",
    "first3 = []\n",
    "first32 = []\n",
    "for tot in range(1,100):\n",
    "    summ = 0\n",
    "    x.append(tot)\n",
    "    first2=0\n",
    "    for i in range(0,tot):\n",
    "        summ += 1./(i+1)\n",
    "        if i < 3:\n",
    "            first = summ\n",
    "            first2 += 1-i/tot\n",
    "\n",
    "\n",
    "    y1.append(1./summ)\n",
    "    y2.append(1/((tot+1)/2))\n",
    "    first3.append(first/summ)\n",
    "    first32.append(first2/((tot+1)/2))\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(15, 10))\n",
    "ax.plot(x,y1, label='First component with 1/i')\n",
    "ax.plot(x,y2, label='First component with 1-i/N')\n",
    "ax.plot(x,first3, label='First 3 component with 1/i')\n",
    "ax.plot(x,first32, label='First 3 component with 1-i/N')\n",
    "ax.set_xlabel('Number of templates', fontsize=15)\n",
    "ax.set_ylabel('Weight of first component', fontsize=15)\n",
    "ax.grid(True, ls=':')\n",
    "ax.vlines(6, 0, 1, colors='r', linestyles='--', label='N=13')\n",
    "ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
