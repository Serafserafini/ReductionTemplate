{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRENDS DIFFERENT SIZE SET1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENERGY ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyfonts import load_font\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# load font\n",
    "helvetica_bold = load_font(\"/home/seraf/Downloads/helvetica-255/Helvetica-Bold.ttf\")\n",
    "helv_bold_prop = FontProperties(fname=\"/home/seraf/Downloads/helvetica-255/Helvetica-Bold.ttf\", size=35)\n",
    "\n",
    "helvetica_strange = load_font(\"/home/seraf/Downloads/helvetica-255/helvetica-light-587ebe5a59211.ttf\")\n",
    "helv_strange_prop = FontProperties(fname=\"/home/seraf/Downloads/helvetica-255/helvetica-light-587ebe5a59211.ttf\", size=20)\n",
    "\n",
    "\n",
    "mother_dir = './HvsINIT/'\n",
    "\n",
    "title = 'SET1 Prediction Performance'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "ax.set_title(title, fontproperties=helv_bold_prop, pad=10)\n",
    "max_x_ticks = np.array([])\n",
    "\n",
    "complist = [1]\n",
    "for comp in complist:\n",
    "    dir_name = f'{comp}'\n",
    "    df_tot = pd.read_csv(mother_dir + f'{dir_name}/TotalStaticsBefore.csv', header=None, na_filter=False, index_col = 0)\n",
    "    tot = (df_tot.to_numpy()).T * 1000\n",
    "\n",
    "    x = np.arange(1, len(tot[0])+1) \n",
    "\n",
    "    ax.plot(x, tot[0] , marker = 'o', markeredgecolor='white', markersize=10, label=f'A$_{comp}$B')\n",
    "    max_x_ticks = np.append(max_x_ticks, len(tot[0]))\n",
    "\n",
    "ax.set_ylabel(r'$\\Delta$H $_{USPEX-TEMP}$ [meV/atom]', fontsize=25, font=helvetica_strange, labelpad=10)\n",
    "step = 20\n",
    "# y_ticks  = np.arange(0,250,step, dtype=float)\n",
    "# ax.set_yticks(y_ticks)\n",
    "# ax.set_yticklabels([f'{i:.0f}' for i in y_ticks])\n",
    "ax.set_ylim(0,250)\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(20))\n",
    "\n",
    "\n",
    "ax.set_xlabel('Size SET1', fontsize=25, font=helvetica_strange, labelpad=10)\n",
    "xticks = np.arange(0, max(max_x_ticks)+1, 10)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xlim(1,max(max_x_ticks)+1)\n",
    "ax.set_xticklabels([f'{i:.0f}' for i in xticks])\n",
    "\n",
    "ax.tick_params(size=7, labelsize=15)\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontproperties(helv_strange_prop)\n",
    "\n",
    "ax.grid(True, ls=':')\n",
    "ax.legend(loc='upper center', prop=helv_strange_prop, ncol=5)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('FIG/A1B.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIZE FINAL SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mother_dir = './HvsINIT/'\n",
    "\n",
    "complist = [1, 2, 3, 4]\n",
    "\n",
    "title = f'SIZE FINAL SET with threshold 0.9'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "fig.suptitle(title, fontsize=20, y=0.95, fontweight='bold')\n",
    "\n",
    "max_x_ticks = np.array([])\n",
    "\n",
    "for comp in complist:\n",
    "    dir_name = f'{comp}'\n",
    "    df_numtemp = pd.read_csv(mother_dir + f'{dir_name}/NumberTempRedu.csv', header=None, na_filter = False, index_col = 0)\n",
    "    numtemp = (df_numtemp.to_numpy()).T\n",
    "    x = np.arange(1, len(numtemp[0])+1)\n",
    "\n",
    "    ax.plot(x, numtemp[0], marker = 'o', markeredgecolor='white', markersize=6, label=f'A$_{comp}$B')\n",
    "    max_x_ticks = np.append(max_x_ticks, len(numtemp[0]))\n",
    "\n",
    "ax.set_ylabel('Size final set', fontsize=22)\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)\n",
    "\n",
    "step = 2\n",
    "y_ticks  = np.arange(0,30,step, dtype=float)\n",
    "y_ticks = np.round(y_ticks, decimals=0)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels([f'{i:.0f}' for i in y_ticks], fontsize=18)\n",
    "ax.set_ylim(0,30)\n",
    "\n",
    "ax.set_xlabel('Size initial set', fontsize=22)\n",
    "ax.xaxis.set_label_coords(0.5, -0.10)\n",
    "\n",
    "xticks = np.arange(1, max(max_x_ticks)+1, 5)\n",
    "xticks = np.round(xticks, decimals=0) \n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xlim(0,max(max_x_ticks)+1)\n",
    "ax.set_xticklabels([f'{i:.0f}' for i in xticks], fontsize=15, rotation=45)\n",
    "\n",
    "ax.grid(True, ls=':')\n",
    "ax.legend(loc='lower right', fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('FIG/INIT_Ntemp.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STD ENERGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mother_dir = './HvsINIT/'\n",
    "\n",
    "title = f'$\\Delta$H w.r.t. USPEX GS with INITIAL SET'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "fig.suptitle(title, fontsize=20, y=0.95, fontweight='bold')\n",
    "max_x_ticks = np.array([])\n",
    "\n",
    "complist = [1,2,3,4]\n",
    "for comp in complist:\n",
    "    dir_name = f'{comp}'\n",
    "    df_tot = pd.read_csv(mother_dir + f'{dir_name}/TotalStaticsBefore.csv', header=None, na_filter=False, index_col = 0)\n",
    "    tot = (df_tot.to_numpy()).T\n",
    "\n",
    "    x = np.arange(1, len(tot[1])+1) \n",
    "\n",
    "    ax.plot(x, tot[1] , marker = 'o', markeredgecolor='white', markersize=6, label=f'A$_{comp}$B')\n",
    "    max_x_ticks = np.append(max_x_ticks, len(tot[1]))\n",
    "\n",
    "\n",
    "ax.set_ylabel(r'$\\Delta$H [eV/atom]', fontsize=22)\n",
    "ax.yaxis.set_label_coords(-0.07, 0.5)\n",
    "\n",
    "step = 0.005\n",
    "y_ticks  = np.arange(0.0,0.1,step, dtype=float)\n",
    "y_ticks = np.round(y_ticks, decimals=2)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels([f'{i:.3f}' for i in y_ticks], fontsize=18)\n",
    "ax.set_ylim(0,0.1)\n",
    "\n",
    "ax.set_xlabel('Size initial set', fontsize=22)\n",
    "ax.xaxis.set_label_coords(0.5, -0.10)\n",
    "\n",
    "xticks = np.arange(1, max(max_x_ticks)+1, 5)\n",
    "xticks = np.round(xticks, decimals=0) \n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xlim(0,max(max_x_ticks)+1)\n",
    "ax.set_xticklabels([f'{i:.0f}' for i in xticks], fontsize=15, rotation=45)\n",
    "\n",
    "ax.grid(True, ls=':')\n",
    "ax.legend(loc='upper right', fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('FIG/INIT_std.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMPLATE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEST TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color_list = ['blue', 'red', 'green', 'purple']\n",
    "comp_list = [1,2,3,4]\n",
    "\n",
    "for idx, comp in enumerate(comp_list):\n",
    "    if comp == 1:\n",
    "        num_pairs = 105\n",
    "    else:\n",
    "        num_pairs = 210\n",
    "    with open(f'ENTHALPY/A{comp}B.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(f'ENTHALPY/EntGS.json', 'r') as f:\n",
    "        gs_dict = json.load(f)\n",
    "\n",
    "    title = r'$\\Delta$H for each template averaged over all pairs'\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(25, 7))\n",
    "\n",
    "    temp_dict = {}\n",
    "\n",
    "    count = 0\n",
    "    for pair in data.keys():\n",
    "        count +=1\n",
    "        for temp in data[pair].keys():\n",
    "            if temp not in temp_dict.keys():\n",
    "                temp_dict[temp] = (data[pair][temp] - gs_dict[f'{comp}'][pair])/num_pairs\n",
    "            else:\n",
    "                temp_dict[temp] += (data[pair][temp] - gs_dict[f'{comp}'][pair])/num_pairs\n",
    "    \n",
    "    # Ordina i template in base ai valori delle entalpie\n",
    "    sorted_items = sorted(temp_dict.items(), key=lambda x: x[1])  \n",
    "    sorted_keys, sorted_values = zip(*sorted_items)  # Divide in due liste ordinate\n",
    "\n",
    "\n",
    "    fig.suptitle(title, fontsize=20, y=0.95, fontweight='bold')\n",
    "    ax.bar(sorted_keys, sorted_values, color=color_list[idx], alpha=0.7)\n",
    "    ax.set_ylabel(r'$\\Delta$H [eV/atom]', fontsize=22, labelpad=10)\n",
    "\n",
    "    ax.set_xlim(-1, len(temp_dict.keys()))\n",
    "    ax.set_xlabel('Template', fontsize=22, labelpad=10)\n",
    "    ax.set_xticks(range(len(sorted_keys)))\n",
    "    fontsize = 12\n",
    "    if comp == 2:\n",
    "        fontsize = 10\n",
    "    ax.set_xticklabels([f'{i.split(\"_\")[0]} {i.split(\"_\")[1]}' for i in sorted_keys], fontsize=fontsize, rotation=90)\n",
    "\n",
    "\n",
    "    ax.grid(True, ls=':', axis='y')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAPTABILITY OVER TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "# Carica i dati\n",
    "with open('ENTHALPY/EntGS.json', 'r') as f:\n",
    "    gs_dict = json.load(f)\n",
    "\n",
    "elements = ['H', 'Li', 'O', 'Na', 'N', 'Mg', 'Si', 'S', 'Be', 'B', 'Al', 'C', 'F', 'P', 'Cl']\n",
    "\n",
    "color_list = ['blue', 'red', 'green', 'purple']\n",
    "\n",
    "for idx, comp in enumerate(gs_dict.keys()):\n",
    "    if comp in ['6']:\n",
    "        continue\n",
    "\n",
    "    pair_count_dict = {}\n",
    "    with open(f'ENTHALPY/A{comp}B.json', 'r') as f:\n",
    "        data_ent = json.load(f)\n",
    "    \n",
    "    for pair in data_ent.keys():\n",
    "        pair_count_dict[pair] = 0\n",
    "        for temp in data_ent[pair].keys():\n",
    "            if data_ent[pair][temp] - gs_dict[comp][pair] < 0.1:\n",
    "                pair_count_dict[pair] += 1\n",
    "\n",
    "    sorted_items = sorted(pair_count_dict.items(), key=lambda x: x[1])  \n",
    "    sorted_keys, sorted_values = zip(*sorted_items)  # Divide in due liste ordinate\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 30))\n",
    "    title = r'Number of templates with $\\Delta$H < 0.1 eV/atom' + f' A$_{comp}$B'\n",
    "    fig.suptitle(title, fontsize=20, y=0.9, fontweight='bold')\n",
    "    \n",
    "    ax.barh(sorted_keys, sorted_values, color=color_list[idx], alpha=0.7)\n",
    "    ax.set_xlabel(r'Number of templates', fontsize=22, labelpad=10, family='serif')\n",
    "\n",
    "    ax.set_ylim(-1, len(pair_count_dict.keys()))\n",
    "    ax.set_ylabel('Pair', fontsize=22, labelpad=10, family='serif')\n",
    "    ax.set_yticks(range(len(sorted_keys)))\n",
    "    fontsize = 12\n",
    "    if comp != '1':\n",
    "        fontsize = 8\n",
    "    ax.set_yticklabels([f'{i}' for i in sorted_keys], fontsize=fontsize)\n",
    "\n",
    "\n",
    "    ax.grid(True, ls=':', axis='y')\n",
    "\n",
    "    \n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRENDS WITHOUT CRITICAL PAIRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCTION OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_csp import managetemp_withdict as mt\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_elements = ['Be', 'B', 'N', 'Mg', 'O', 'Li', 'C', 'Na', 'Si', 'S', 'Cl', 'F', 'P', 'H', 'Al']\n",
    "\n",
    "hyperparameters = { \n",
    "    \"weight_occurrence\" : 1,\n",
    "    \"weight_sg\" : 0.001,\n",
    "    \"weight_formation_entalphy\" : 1, \n",
    "    \"comp\" : 1,\n",
    "    \"lev_red\" : 0.9,\n",
    "    \"n_pairs\" : 105,\n",
    "\n",
    "    \"n_final_templates\" : 1\n",
    "}\n",
    "\n",
    "\n",
    "complist = [1, 2, 3, 4] \n",
    "initlist = [86, 156, 92, 79] # 86 \n",
    "mother_dir = './HvsINIT/'\n",
    "path_to_critical_pairs = 'CriticalPairs.json'\n",
    "\n",
    "for comp in complist:\n",
    "    dir_comp = mother_dir + f'{comp}/'\n",
    "    means = np.zeros(initlist[complist.index(comp)])\n",
    "    stds = np.zeros(initlist[complist.index(comp)])\n",
    "\n",
    "    for size_initial in tqdm(range(1, initlist[complist.index(comp)]+1)):\n",
    "        dir_init = dir_comp + f'{size_initial}/'\n",
    "        errors_bef = np.zeros(20)\n",
    "\n",
    "        \n",
    "        for step in range(0,20):\n",
    "            file_restart = dir_init + f'TemplateSet_{step}'\n",
    "\n",
    "            initial_set = mt.TemplateSet(test_elements=test_elements, hyperparameters=hyperparameters, restart_file=file_restart, comp = comp)\n",
    "            errors_bef[step] = initial_set.err_before(path_to_critical_pairs)\n",
    "\n",
    "        means[size_initial-1] = np.mean(errors_bef)\n",
    "        stds[size_initial-1] = np.std(errors_bef)\n",
    "\n",
    "        if size_initial == 1:\n",
    "            with open(dir_comp + 'BeforeNoCritical0.csv', 'w') as f:\n",
    "                f.write(f'{size_initial-1},{means[size_initial-1]},{stds[size_initial-1]}\\n')\n",
    "        else:\n",
    "            with open(dir_comp + 'BeforeNoCritical0.csv', 'a') as f:\n",
    "                f.write(f'{size_initial-1},{means[size_initial-1]},{stds[size_initial-1]}\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "mother_dir = './HvsINIT/'\n",
    "\n",
    "crit_pairs = {}\n",
    "with open('CriticalPairs.json', 'r') as f:\n",
    "    crit_pairs = json.load(f)\n",
    "\n",
    "\n",
    "title = r'$\\Delta$H w.r.t. USPEX GS with INITIAL SET'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7))\n",
    "fig.subplots_adjust(hspace=0.0)\n",
    "fig.suptitle(title, fontsize=25, y=0.95, fontweight='bold')\n",
    "max_x_ticks = np.array([])\n",
    "\n",
    "complist = [1,2,3,4]\n",
    "for comp in complist:\n",
    "    dir_name = f'{comp}'\n",
    "    df_tot = pd.read_csv(mother_dir + f'{dir_name}/BeforeNoCritical0.csv', header=None, na_filter=False, index_col = 0)\n",
    "    tot = (df_tot.to_numpy()).T * 1000\n",
    "\n",
    "    x = np.arange(1, len(tot[0])+1) \n",
    "\n",
    "    ax.plot(x, tot[0] , marker = 'o', markeredgecolor='white', markersize=8, label=f'A$_{comp}$B - {len(crit_pairs[f\"{comp}\"])} excluded')\n",
    "    max_x_ticks = np.append(max_x_ticks, len(tot[0]))\n",
    "\n",
    "\n",
    "ax.set_ylabel(r'$\\Delta$H [meV/atom]', fontsize=22, labelpad=10, family='serif')\n",
    "step = 20\n",
    "y_ticks  = np.arange(0,150,step, dtype=float)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels([f'{i:.0f}' for i in y_ticks], fontsize=18)\n",
    "ax.set_ylim(0,150)\n",
    "\n",
    "ax.set_xlabel('SIZE INITIAL SET', fontsize=22, labelpad=10, family='serif')\n",
    "xticks = np.arange(0, max(max_x_ticks)+1, 10)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xlim(1,max(max_x_ticks)+1)\n",
    "ax.set_xticklabels([f'{i:.0f}' for i in xticks], fontsize=18)\n",
    "\n",
    "ax.grid(True, ls=':')\n",
    "ax.legend(loc='upper right', fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('FIG/INIT_H_noCritical.png', bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template_csp import manage_alltemp as mte \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_elements = ['Be', 'B', 'N', 'Mg', 'O', 'Li', 'C', 'Na', 'Si', 'S', 'Cl', 'F', 'P', 'H', 'Al']\n",
    "\n",
    "hyperparameters = { \n",
    "    \"weight_occurrence\" : 1,\n",
    "    \"weight_sg\" : 0.001,\n",
    "    \"weight_formation_entalphy\" : 1, \n",
    "    \"comp\" : 1,\n",
    "    \"lev_red\" : 0.9,\n",
    "    \"n_pairs\" : 105,\n",
    "\n",
    "    \"n_template\" : 1,\n",
    "\n",
    "    \"n_final_templates\" : 1,\n",
    "    \"job_id\" : 0\n",
    "    #\"critical_pairs\" : './CriticalPairs.json'\n",
    "}\n",
    "\n",
    "data = {}\n",
    "data1 = {}\n",
    "\n",
    "complist = [1,2,3,4,6]\n",
    "temp_list = [[20,30,40], [40,50,60], [30,40,50], [30,40,50], [20,30,40]] \n",
    "temp_final = [10, 20, 15, 15, 10]\n",
    "#total_pairs_list = [95, 180, 175, 171, 210]\n",
    "total_pairs_list = None\n",
    "n_set = 20\n",
    "n_try_pairs = 30\n",
    "\n",
    "crit_pairs = './CriticalPairs.json'\n",
    "\n",
    "for comp, temp_init_list in tqdm(zip(complist, temp_list)):\n",
    "    \n",
    "    if comp == 6:\n",
    "        continue\n",
    "\n",
    "    hyperparameters[\"comp\"] = comp\n",
    "    \n",
    "    if total_pairs_list:\n",
    "        total_pairs = total_pairs_list[complist.index(comp)]\n",
    "    else:\n",
    "        if comp == 1:\n",
    "            total_pairs = 105\n",
    "        else:\n",
    "            total_pairs = 210\n",
    "\n",
    "    data[comp] = {'ErrBef': {}, 'ErrAft': {}}\n",
    "    data1[comp] = {}\n",
    "\n",
    "    hyperparameters['n_final_templates'] = temp_final[complist.index(comp)]\n",
    "\n",
    "    for idx_temp, temp_init in enumerate(temp_init_list):\n",
    "\n",
    "        data[comp]['ErrBef'][temp_init] = 0\n",
    "        data[comp]['ErrAft'][temp_init] = {}\n",
    "        data1[comp][temp_init] = {}    \n",
    "\n",
    "        for id_set in range(n_set):\n",
    "\n",
    "            init_set = mte.InitialSet(test_elements, hyperparameters, 'InitialSet.txt')\n",
    "            # init_set.recap()\n",
    "            \n",
    "            data[comp]['ErrBef'][temp_init] += init_set.difference_from_uspex()/n_set\n",
    "            \n",
    "            for idx_npair, npair in enumerate(range(1, total_pairs, 5)):\n",
    "\n",
    "                if npair not in data[comp]['ErrAft'][temp_init].keys():\n",
    "                    data[comp]['ErrAft'][temp_init][npair] = 0\n",
    "                    data1[comp][temp_init][npair] = 0\n",
    "\n",
    "                hyperparameters[\"n_pairs\"] = npair\n",
    "                \n",
    "                for try_pairs in range(n_try_pairs):\n",
    "                    final_set = mte.FinalSet(init_set, test_elements, hyperparameters, 'FinalSet.txt')\n",
    "                    \n",
    "                    data[comp]['ErrAft'][temp_init][npair] += final_set.difference_from_uspex()/(n_set*n_try_pairs)\n",
    "                    data1[comp][temp_init][npair] += float(final_set.count_crit_in_validation)/(n_set*n_try_pairs)\n",
    "\n",
    "                    # final_set.recap()\n",
    "        \n",
    "            \n",
    "            npair = total_pairs\n",
    "            hyperparameters[\"n_pairs\"] = npair\n",
    "\n",
    "            final_set = mte.generate_final_set(init_set, hyperparameters=hyperparameters, test_elements=test_elements, file_crit_pairs = crit_pairs)\n",
    "            if npair not in data[comp]['ErrAft'][temp_init].keys():\n",
    "                data[comp]['ErrAft'][temp_init][npair] = 0\n",
    "                data1[comp][temp_init][npair] = 0\n",
    "            \n",
    "            data1[comp][temp_init][npair] += float(final_set.count_crit_in_validation)/n_set\n",
    "            data[comp]['ErrAft'][temp_init][npair] += final_set.difference_from_uspex()/n_set\n",
    "\n",
    "            with open('./NumberOfPairs_Continuum.json', 'w') as f:\n",
    "                json.dump(data, f, indent=4)\n",
    "                \n",
    "            with open('./UsedCritPairs.json', 'w') as f:\n",
    "                json.dump(data1, f, indent=4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
