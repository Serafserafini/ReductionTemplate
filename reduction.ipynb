{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from pymatgen.core import Element\n",
    "from pymatgen.io.vasp import Poscar\n",
    "from pymatgen.io.cif import CifWriter\n",
    "from pymatgen.core import Composition\n",
    "from pymatgen.analysis.structure_matcher import StructureMatcher\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "##---------PREPARE INPUTS VC-RELAX FROM CIF--------##\n",
    "\n",
    "AtomSymb = np.asarray([str(e) for e in Element])[2:]\n",
    "AtomMass = np.asarray([str(float(Element(e).atomic_mass)) for e in AtomSymb]) \n",
    "\n",
    "qe_input = {\"calculation_type\" : \"vc-relax\", \n",
    "\"pseudo_dir\" : \"./pseudo\",\n",
    "\"pseudo_tail\" : \"_ONCV_PBE_sr.upf\",\n",
    "\"ecutwfc\" : 80,\n",
    "\"occupations_scf\" : \"smearing\",\n",
    "\"smearing_scf\" : \"marzari-vanderbilt\",\n",
    "\"degauss_scf\" : 0.02,\n",
    "\"el_conv_thr\" : 1.0e-7,\n",
    "\"mixing_beta\" : 0.7,\n",
    "\"ion_dynamics\" : \"bfgs\",\n",
    "\"cell_dofree\" : \"ibrav\",\n",
    "\"cell_dynamics\" : \"bfgs\",\n",
    "\"press\" : 500.0,\n",
    "\"kspacing_scf\" : 0.25,\n",
    "\"kspacing_nscf\" : 0.10,\n",
    "\"forc_conv_thr\" : 1e-3,\n",
    "\"etot_conv_thr\" : 1e-5,\n",
    "\"cell_factor\" : 4.0 }\n",
    "\n",
    "\n",
    "bohr_to_angstrom = 0.52917720859 # Bohr radius\n",
    "grk_pi = 3.14159265358979323846  # pi\n",
    "rad_to_deg = 180 / grk_pi        # from radians to degrees\n",
    "\n",
    "#a, b, c are input qe parameters\n",
    "def make_kmesh(a, b, c, spacing = 0.30):\n",
    "    KP_x = int(2.*grk_pi / (a * spacing) + 0.5)\n",
    "    if KP_x < 1:\n",
    "        KP_x = 1\n",
    "    KP_y = int(2.*grk_pi / (b * spacing) + 0.5)\n",
    "    if KP_y < 1:\n",
    "        KP_y = 1\n",
    "    KP_z = int(2.*grk_pi / (c * spacing) + 0.5)\n",
    "    if KP_z < 1:\n",
    "        KP_z = 1\n",
    "    return [KP_x, KP_y, KP_z]  ## number of kpoints in each direction\n",
    "\n",
    "# Given ibrav value and angle in rad returns the lattice vectors of primitive and conventional cell\n",
    "def get_bravais_vectors(ibrav, alphar, betar, gammar):\n",
    "    if ibrav == 1:\n",
    "        ## 1: simple_cubic\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        return conventional, primitive\n",
    "    elif ibrav == 2:\n",
    "        ## 2: face_centered_cubic\n",
    "        conventional =  np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[-1/2,0,1/2],\n",
    "                                 [0,1/2,1/2],\n",
    "                                 [-1/2,1/2,0]])\n",
    "    elif ibrav == 3:\n",
    "        ## 3: body_centered_cubic\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1/2,1/2,1/2],\n",
    "                                 [-1/2,1/2,1/2],\n",
    "                                 [-1/2,-1/2,1/2]])\n",
    "    elif ibrav == 4:\n",
    "        ## 4: simple_hexagonal\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [-1/2,np.sqrt(3)/2,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [-1/2,np.sqrt(3)/2,0],\n",
    "                                 [0,0,1]])\n",
    "    elif ibrav == 5:\n",
    "        raise Warning(\"Trigonal axes not yet implemented.\")\n",
    "    elif ibrav == -5:\n",
    "        raise Warning(\"Trigonal axes not yet implemented.\")\n",
    "    \n",
    "    elif ibrav == 6:\n",
    "    ## 6: simple_tetragonal\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "    elif ibrav == 7:\n",
    "        ## 7: body_centered_tetragonal\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive =  np.asarray([[1/2,-1/2,1/2],\n",
    "                                 [1/2,1/2,1/2],\n",
    "                                 [-1/2,-1/2,1/2]])\n",
    "    elif ibrav == 8:\n",
    "        ## 8: orthorhombic_simple\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "    elif ibrav == 9:\n",
    "        ## 9: orthorhombic_base_centered\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1/2,1/2,0],\n",
    "                                 [-1/2,1/2,0],\n",
    "                                 [0,0,1]])\n",
    "    elif ibrav == -9:\n",
    "        ## -9: orthorhombic_base_centered\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1/2,-1/2,0],\n",
    "                                 [1/2,1/2,0],\n",
    "                                 [0,0,1]])\n",
    "    elif ibrav == 91:\n",
    "     ## 91: orthorhombic_one_base_centered_a_type\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [0,1/2,-1/2],\n",
    "                                 [0,1/2,1/2]])\n",
    "    elif ibrav == 10:\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1/2,0,1/2],\n",
    "                                 [1/2,1/2,0],\n",
    "                                 [0,1/2,1/2]])\n",
    "    elif ibrav == 11:\n",
    "        ## 11: body_centered_orthorhombic\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [0,0,1]])\n",
    "        primitive = np.asarray([[1/2,1/2,1/2],\n",
    "                                 [-1/2,1/2,1/2],\n",
    "                                 [-1/2,-1/2,1/2]])\n",
    "    elif ibrav == 12:\n",
    "        ## 12: monoclinic, unique axis c\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [np.cos(gammar),0,np.sin(gammar)],\n",
    "                                 [0, 0, 1]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [np.cos(gammar),0,np.sin(gammar)],\n",
    "                                 [0, 0, 1]])\n",
    "    elif ibrav == -12:\n",
    "        ## -12: monoclinic, unique axis b\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [np.cos(betar),0,np.sin(betar)]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [np.cos(betar),0,np.sin(betar)]])\n",
    "    elif ibrav == 13:\n",
    "        ## 13: monoclinic, unique axis c\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [np.cos(gammar),0,np.sin(gammar)],\n",
    "                                 [0, 0, 1]])\n",
    "        primitive = np.asarray([[1/2,0,-1/2],\n",
    "                                 [np.cos(gammar),np.sin(gammar),0],\n",
    "                                 [1/2, 0, 1/2]])\n",
    "    elif ibrav == -13:\n",
    "        ## -13: monoclinic base-centered, unique axis b\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [0,1,0],\n",
    "                                 [np.cos(betar),0,np.sin(betar)]])\n",
    "        primitive = np.asarray([[1/2,1/2,0],\n",
    "                                 [-1/2,1/2,0],\n",
    "                                 [np.cos(betar),0,np.sin(betar)]])\n",
    "    elif ibrav == 14:\n",
    "        ## 14: triclinic, I hope this is never ever called\n",
    "        conventional = np.asarray([[1,0,0],\n",
    "                                 [np.cos(gammar), np.sin(gammar),0],\n",
    "                                 [np.cos(betar),\n",
    "                                  (np.cos(alphar)-np.cos(betar)*np.cos(gammar))/np.sin(gammar),\n",
    "                                  np.sqrt(1+2*np.cos(alphar)*np.cos(betar)*np.cos(gammar)-np.cos(alphar)**2-np.cos(betar)**2-np.cos(gammar)**2)/np.sin(gammar)]])\n",
    "        primitive = np.asarray([[1,0,0],\n",
    "                                 [np.cos(gammar), np.sin(gammar),0],\n",
    "                                 [np.cos(betar),\n",
    "                                  (np.cos(alphar)-np.cos(betar)*np.cos(gammar))/np.sin(gammar),\n",
    "                                  np.sqrt(1+2*np.cos(alphar)*np.cos(betar)*np.cos(gammar)-np.cos(alphar)**2-np.cos(betar)**2-np.cos(gammar)**2)/np.sin(gammar)]])\n",
    "    else:\n",
    "        raise Warning(\"No valid ibrav found, which should never happen, ibrav is: \" + str(ibrav))\n",
    "    return conventional, primitive\n",
    "\n",
    "def check_and_add_position_primitive(new_coord, new_atom, coord_list, type_list, direct_lattice, threshold=0.001):\n",
    "    list_operations = []\n",
    "    for i in range(-3, 3, 1): ## vector a1 up to 4 cells away in all directions\n",
    "        for j in range(-3, 3, 1): ## vector a2 up to 4 cells away in all directions\n",
    "            for k in range(-3, 3, 1): ## vector a3 up to 4 cells away in all directions\n",
    "                list_operations.append(direct_lattice[:,0]*i + direct_lattice[:,1]*j + direct_lattice[:,2]*k)\n",
    "\n",
    "    for operation in list_operations:\n",
    "        for old_coord in coord_list:\n",
    "                ## compare element by element whether old_coord and new_coord + operation are all the same or not\n",
    "                ## if they are the same, do not add this atom\n",
    "            if all(abs(a - b) <= threshold for a, b in zip(np.asarray(old_coord), new_coord+np.asarray(operation))):\n",
    "                return coord_list, type_list\n",
    "    ## if the code arrives here it means that this atomic position is not equivalent to the previous ones\n",
    "    coord_list.append(new_coord)\n",
    "    type_list.append(new_atom)\n",
    "    return coord_list, type_list\n",
    "\n",
    "## write necessary celldm parameters for each ibrav\n",
    "def write_celldm(file, qe_input, qe_parameters):\n",
    "    if int(qe_parameters[\"ibrav\"]) != 0:\n",
    "        file.write(\"   ibrav = \" + str(int(qe_parameters[\"ibrav\"])) + \" \\n\")\n",
    "        file.write(\"   nat = \" + str(int(qe_parameters[\"nat\"])) + \" \\n\")\n",
    "        file.write(\"   ntyp = \" + str(int(qe_parameters[\"ntyp\"])) + \" \\n\")\n",
    "        file.write(\"   celldm(1) = \" + str(qe_parameters[\"a\"]/bohr_to_angstrom) + \" \\n\")\n",
    "        if qe_parameters[\"ibrav\"] in [4, 6, 7]:\n",
    "            file.write(\"   celldm(3) = \" + str(qe_parameters[\"c\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] in [5, -5]:\n",
    "            file.write(\"   celldm(4) = \" + str(np.cos(qe_parameters[\"alphar\"])) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] == 14:\n",
    "            file.write(\"   celldm(2) = \" + str(qe_parameters[\"b\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(3) = \" + str(qe_parameters[\"c\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(4) = \" + str(np.cos(qe_parameters[\"alphar\"])) + \" \\n\")\n",
    "            file.write(\"   celldm(5) = \" + str(np.cos(qe_parameters[\"betar\"])) + \" \\n\")\n",
    "            file.write(\"   celldm(6) = \" + str(np.cos(qe_parameters[\"gammar\"])) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] == -12:\n",
    "            file.write(\"   celldm(2) = \" + str(qe_parameters[\"b\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(3) = \" + str(qe_parameters[\"c\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(5) = \" + str(np.cos(qe_parameters[\"betar\"])) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] == 13:\n",
    "            file.write(\"   celldm(2) = \" + str(qe_parameters[\"b\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(3) = \" + str(qe_parameters[\"c\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(4) = \" + str(np.cos(qe_parameters[\"alphar\"])) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] in [8, 9, 10, 11]:\n",
    "            file.write(\"   celldm(2) = \" + str(qe_parameters[\"b\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(3) = \" + str(qe_parameters[\"c\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] == 12:\n",
    "            file.write(\"   celldm(2) = \" + str(qe_parameters[\"b\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(3) = \" + str(qe_parameters[\"c\"]/qe_parameters[\"a\"]) + \" \\n\")\n",
    "            file.write(\"   celldm(4) = \" + str(np.cos(qe_parameters[\"alphar\"])) + \" \\n\")\n",
    "        elif qe_parameters[\"ibrav\"] in [1, 2, 3]:\n",
    "            pass\n",
    "\n",
    "#Write base layer of the input file\n",
    "def write_qe_input_lowlevel(file, qe_input, qe_parameters):\n",
    "    ## Control   \n",
    "    calculation_type = qe_input[\"calculation_type\"]\n",
    "\n",
    "    file.write(\"&CONTROL \\n\")\n",
    "    file.write(\"   calculation = '\" + calculation_type + \"'\\n\")\n",
    "    file.write(\"   restart_mode = 'from_scratch' \\n\")\n",
    "    prefix = qe_parameters[\"chemical_formula\"]\n",
    "    file.write(\"   prefix = '\" + prefix + \"' \\n\")\n",
    "    file.write(\"   tstress = .true. \\n\")\n",
    "    file.write(\"   tprnfor = .true. \\n\")\n",
    "    file.write(\"   pseudo_dir = '\" + qe_input[\"pseudo_dir\"] + \"' \\n\")\n",
    "    file.write(\"   outdir = './output' \\n\")\n",
    "    file.write(\"   forc_conv_thr = \" + str(qe_input[\"forc_conv_thr\"]) + \"\\n\")\n",
    "    file.write(\"   etot_conv_thr = \" + str(qe_input[\"etot_conv_thr\"]) + \"\\n\")\n",
    "    file.write(\"&end \\n\")\n",
    "    ## System\n",
    "    file.write(\"&SYSTEM \\n\")\n",
    "    write_celldm(file, qe_input, qe_parameters)\n",
    "    file.write(\"   ecutwfc = \" + str(qe_input[\"ecutwfc\"]) + \" \\n\")\n",
    "    file.write(\"   occupations = '\" + qe_input[\"occupations_scf\"] + \"' \\n\")\n",
    "    file.write(\"   smearing = '\" + qe_input[\"smearing_scf\"] + \"' \\n\")\n",
    "    file.write(\"   degauss = \" + str(qe_input[\"degauss_scf\"]) + \" \\n\")\n",
    "    file.write(\"&end \\n\")\n",
    "    ## Electrons\n",
    "    file.write(\"&ELECTRONS \\n\")\n",
    "    file.write(\"   conv_thr =  \" + str(float(qe_input[\"el_conv_thr\"])) + \" \\n\")\n",
    "    file.write(\"   mixing_beta = \" + str(qe_input[\"mixing_beta\"]) + \" \\n\")\n",
    "    file.write(\"&end \\n\")\n",
    "    ## Ions\n",
    "    file.write(\"&IONS \\n\")\n",
    "    file.write(\"   ion_dynamics = '\" + qe_input[\"ion_dynamics\"] + \"' \\n\")\n",
    "    file.write(\"&end \\n\")\n",
    "    ## Cell\n",
    "    file.write(\"&CELL \\n\")\n",
    "    file.write(\"   cell_dynamics = '\" + qe_input[\"cell_dynamics\"] + \"' \\n\")\n",
    "    file.write(\"   cell_dofree = '\" + qe_input[\"cell_dofree\"] + \"' \\n\")\n",
    "    #file.write(\"   cell_factor = \" + str(float(qe_input[\"cell_factor\"])) + \" \\n\")\n",
    "    file.write(\"   press = \" + str(float(qe_input[\"press\"])) + \" \\n\")\n",
    "    file.write(\"&end \\n\")\n",
    "    file.write(\"\\n\")\n",
    "    ## Atomic species\n",
    "    file.write(\"ATOMIC_SPECIES \\n\")\n",
    "    for i, specie in enumerate(qe_parameters[\"atomic_species\"]):\n",
    "        file.write(\"   \" + specie + \"   \" + str(qe_parameters[\"atomic_masses\"][i]) + \"    \" + specie + qe_input[\"pseudo_tail\"] + \" \\n\")\n",
    "    file.write(\"\\n\")\n",
    "    ## Atomic positions\n",
    "    file.write(\"ATOMIC_POSITIONS crystal \\n\")\n",
    "    for i, atom in enumerate(qe_parameters[\"atomic_coordinates\"]):\n",
    "        file.write(\"   \" + qe_parameters[\"atomic_coordinates_types\"][i] + \"    \" + \n",
    "                   str(qe_parameters[\"atomic_coordinates\"][i][0]) + \"    \" + \n",
    "                   str(qe_parameters[\"atomic_coordinates\"][i][1]) + \"    \" + \n",
    "                   str(qe_parameters[\"atomic_coordinates\"][i][2]) + \"    \\n\")\n",
    "    ## K_POINTS\n",
    "    file.write(\"K_POINTS automatic \\n\")\n",
    "    if \"kspacing_scf\" in list(qe_input.keys()):\n",
    "        kpoints = make_kmesh(qe_parameters[\"a\"], qe_parameters[\"b\"], qe_parameters[\"c\"], spacing=qe_input[\"kspacing_scf\"])\n",
    "    else: \n",
    "        kpoints = make_kmesh(qe_parameters[\"a\"], qe_parameters[\"b\"], qe_parameters[\"c\"], spacing=0.30)\n",
    "    file.write(str(kpoints[0]) + \"  \" + str(kpoints[1]) + \"  \" + str(kpoints[2]) + \"    0  0  0 \" + \" \\n\")\n",
    "\n",
    "## Apply symmetry operation to a vector position to get a new vector position\n",
    "def apply_symm_op(vec_pos, symm_op):\n",
    "    x, y, z = vec_pos[0], vec_pos[1], vec_pos[2]\n",
    "    new_vec_pos= [None, None, None]\n",
    "    for i, coord in enumerate(symm_op):\n",
    "        ## Replace symbolic coordinates with values\n",
    "        op = symm_op[i].replace(\"x\", \"+\"+str(x)).replace(\"y\", \"+\"+str(y)).replace(\"z\", \"+\"+str(z))\n",
    "        ## Algebraic sign rules\n",
    "        op = op.replace(\"--\", \"+\").replace(\"-+\", \"-\").replace(\"+-\", \"-\").replace(\"++\", \"+\")\n",
    "        new_vec_pos[i] = float(eval(op))\n",
    "        while new_vec_pos[i] < 0 :\n",
    "            new_vec_pos[i] += 1.\n",
    "        while new_vec_pos[i] >= 1. :\n",
    "            new_vec_pos[i] -= 1.\n",
    "    return new_vec_pos\n",
    "    \n",
    "## Function to identify Bravais lattice from lattice parameters\n",
    "def find_lattice(a, b, c, alpha, beta, gamma):\n",
    "    thr = 1.e-4\n",
    "    bravais = \"\"\n",
    "    if abs(alpha - 90.0) < thr and abs(gamma - 90.0) < thr:\n",
    "        if abs(beta - 90.0) < thr:\n",
    "            if abs(a - b) < thr and abs(a - c) < thr:\n",
    "                bravais = \"cubic\"\n",
    "            elif abs(a - b) < thr:\n",
    "                bravais = \"tetragonal\"\n",
    "            else:\n",
    "                bravais = \"orthorhombic\"\n",
    "        else:\n",
    "            bravais = \"monoclinic\"\n",
    "    elif abs(alpha - 90.0) < thr and abs(beta - 90.0) < thr and abs(gamma - 120.0) < thr:\n",
    "        bravais = \"hexagonal\"\n",
    "    elif abs(alpha - beta) < thr and abs(alpha - gamma) < thr and abs(a - b) < thr and abs(a - c) < thr:\n",
    "        bravais = \"rhombohedral\"\n",
    "    else:\n",
    "        bravais = \"triclinic\"\n",
    "    return bravais\n",
    "\n",
    "## Function to find ibrav\n",
    "def find_ibrav(spacegroup, bravais):\n",
    "    ibrav = 0\n",
    "    primitive = re.search(\"P\", spacegroup) is not None\n",
    "    bodycentered = re.search(\"I\", spacegroup) is not None\n",
    "    facecentered = re.search(\"F\", spacegroup) is not None\n",
    "    basecentered = re.search(\"C\", spacegroup) is not None\n",
    "    onefacebasecentered = re.search(\"A\", spacegroup) is not None\n",
    "\n",
    "    if bravais == \"cubic\":\n",
    "        if primitive:\n",
    "            ibrav = 1\n",
    "        if facecentered:\n",
    "            ibrav = 2\n",
    "        if bodycentered:\n",
    "            ibrav = 3\n",
    "    elif bravais == \"tetragonal\":\n",
    "        if primitive:\n",
    "            ibrav = 6\n",
    "        if bodycentered:\n",
    "            ibrav = 7\n",
    "    elif bravais == \"orthorhombic\":\n",
    "        if primitive:\n",
    "            ibrav = 8\n",
    "        if basecentered:\n",
    "            ibrav = 9\n",
    "        if onefacebasecentered:\n",
    "            ibrav = 91\n",
    "        if facecentered:\n",
    "            ibrav = 10\n",
    "        if bodycentered:\n",
    "            ibrav = 11\n",
    "    elif bravais == \"monoclinic\":\n",
    "        if primitive:\n",
    "            ibrav = -12\n",
    "        if basecentered:\n",
    "            ibrav = 13\n",
    "    elif bravais == \"triclinic\":\n",
    "        ibrav = 14\n",
    "    elif bravais == \"hexagonal\":\n",
    "        ibrav = 4\n",
    "    elif bravais == \"rhombohedral\":\n",
    "        if primitive:\n",
    "            ibrav = 4\n",
    "        else:\n",
    "            ibrav = 5\n",
    "    else:\n",
    "        ibrav = 0\n",
    "    return ibrav\n",
    "\n",
    "class PWSCf_input:\n",
    "    def __init__(self, qe_input, cifname=None):\n",
    "        self.name = None   ## name/identifier for structure\n",
    "        self.cifname = cifname\n",
    "        self.qe_input = qe_input\n",
    "        ## Tolerance for recognizing identical atoms generated by symmetry\n",
    "        self.threshold = 0.01\n",
    "        self.totatom = 0\n",
    "        self.num_symm_op = 0\n",
    "        ## Store all symmetry operations\n",
    "        self.symm_op_list = []\n",
    "        ## Store atomic coordinates (pre sym-op)\n",
    "        self.atomic_type_list = []\n",
    "        self.atomic_coord_list = []\n",
    "        self.qe_parameters = {}\n",
    "        ## Store atomic coordinates and atom type (post sym-op)\n",
    "        self.atomic_coord_list_extended = []\n",
    "        self.atomic_type_list_extended = []\n",
    "        ## Store list of atomic masses\n",
    "        self.atomic_masses = []\n",
    "        ## Internal consistency checks\n",
    "        self.relax_read = False\n",
    "        ## Relaxation checks\n",
    "        self.off_diagonal_ok = None\n",
    "        self.restart_diff_ok = None\n",
    "        self.restart_forces_ok = None\n",
    "\n",
    "    ## Reading keywords in cif file and add them to qe_parameters dictionary\n",
    "    def read_cif(self):\n",
    "        ## Token to count lines with symmetry operations\n",
    "        count_symm_finished = False\n",
    "        start_match = False\n",
    "        ## Token to read lines with atomic positions\n",
    "        start_readatoms = False\n",
    "        with open(self.cifname) as cif_file:\n",
    "            for line in cif_file.readlines():\n",
    "                if \"_symmetry_space_group_name_H-M\" in line:\n",
    "                    tmpspacegroup = line.split()[1]\n",
    "                    self.qe_parameters[\"HMsg\"] = tmpspacegroup\n",
    "                elif \"_cell_length_a\" in line:\n",
    "                    a = float(line.split()[1])\n",
    "                    self.qe_parameters[\"a\"] = a\n",
    "                elif \"_cell_length_b\" in line:\n",
    "                    b = float(line.split()[1])\n",
    "                    self.qe_parameters[\"b\"] = b\n",
    "                elif \"_cell_length_c\" in line:\n",
    "                    c = float(line.split()[1])\n",
    "                    self.qe_parameters[\"c\"] = c\n",
    "                elif \"_cell_angle_alpha\" in line:\n",
    "                    alpha = float(line.split()[1])\n",
    "                    self.qe_parameters[\"alpha\"] = alpha\n",
    "                    self.qe_parameters[\"alphar\"] = alpha / 180.0 * grk_pi\n",
    "                    self.qe_parameters[\"cosab\"] = np.cos(alpha / 180.0 * grk_pi)\n",
    "                elif \"_cell_angle_beta\" in line:\n",
    "                    beta = float(line.split()[1])\n",
    "                    self.qe_parameters[\"beta\"] = beta\n",
    "                    self.qe_parameters[\"betar\"] = beta / 180.0 * grk_pi\n",
    "                    self.qe_parameters[\"cosbc\"] = np.cos(beta / 180.0 * grk_pi)\n",
    "                elif \"_cell_angle_gamma\" in line:\n",
    "                    gamma = float(line.split()[1])\n",
    "                    self.qe_parameters[\"gamma\"] = gamma\n",
    "                    self.qe_parameters[\"gammar\"] = gamma / 180.0 * grk_pi\n",
    "                    self.qe_parameters[\"cosac\"] = np.cos(gamma / 180.0 * grk_pi)\n",
    "                elif \"_symmetry_Int_Tables_number\" in line:\n",
    "                    tmptablenumber = int(line.split()[1])\n",
    "                    self.qe_parameters[\"NUMsg\"] = tmptablenumber\n",
    "                elif \"_chemical_formula_structural\" in line:\n",
    "                    chemical_formula = line.split()[1]\n",
    "                    self.qe_parameters[\"chemical_formula\"] = chemical_formula\n",
    "                elif \"_chemical_formula_sum\" in line:\n",
    "                    chemical_formula_sum = line.replace(\"'\",\"\").split()[1:]\n",
    "                    self.qe_parameters[\"formula_sum\"] = chemical_formula_sum\n",
    "                ## Count symmetry operations\n",
    "                elif \" _symmetry_equiv_pos_as_xyz\" in line:\n",
    "                    start_match = True\n",
    "                elif start_match and not count_symm_finished:\n",
    "                    self.num_symm_op += 1\n",
    "                if (\"loop_\" in line) and start_match:\n",
    "                    count_symm_finished = True\n",
    "                    start_match = False\n",
    "                    self.num_symm_op -= 1\n",
    "                if start_match and self.num_symm_op > 0 :\n",
    "                    self.symm_op_list.append(line.split(\"'\")[1].replace(\"'\",\"\").replace(\",\",\"\").split())\n",
    "                ## Count symmetry operation ends\n",
    "                ## Read atom type and coordinate begins\n",
    "                if start_readatoms and line.strip():\n",
    "                    self.atomic_coord_list.append(line.split()[3:6])\n",
    "                    self.atomic_type_list.append(line.split()[0])\n",
    "                if \"_atom_site_occupancy\" in line:\n",
    "                    start_readatoms = True\n",
    "                ## Read atom type and coordinate ends\n",
    "        self.data_read = True\n",
    "        self.generate_cell_data()\n",
    "        self.generate_coords_sym()\n",
    "        self.get_unique_atoms_list()\n",
    "        self.name = self.qe_parameters[\"chemical_formula\"] + \"_\" + str(self.qe_parameters[\"NUMsg\"])\n",
    "\n",
    "    ## Write the input file for Quantum Espresso\n",
    "    def write_scf_input(self, qe_input_name=\"pw.scf.in\"):\n",
    "        if self.data_read:\n",
    "            with open(qe_input_name, \"w\") as qe_input_file:\n",
    "                write_qe_input_lowlevel(qe_input_file, self.qe_input, self.qe_parameters)\n",
    "        else:\n",
    "            print(\"Data was not read!\")\n",
    "\n",
    "    ## Get the name of atoms without repetition\n",
    "    def get_unique_atoms_list(self):\n",
    "        _, idx = np.unique(np.asarray(self.atomic_type_list_extended), return_index=True)\n",
    "        self.qe_parameters[\"atomic_species\"] = np.asarray(self.atomic_type_list_extended)[np.sort(idx)].tolist()\n",
    "        for element in self.qe_parameters[\"atomic_species\"]:\n",
    "            self.atomic_masses.append(float(AtomMass[np.isin(AtomSymb, element)][0]))\n",
    "        self.qe_parameters[\"atomic_masses\"] = self.atomic_masses  \n",
    "\n",
    "    def generate_coords_sym(self):\n",
    "        if self.data_read:\n",
    "            for a_i, atomic_coord in enumerate(self.atomic_coord_list):\n",
    "                for symm_op in self.symm_op_list:\n",
    "                    ## generate a new equivalent position using the allowed symmetry operations\n",
    "                    eq_coord = apply_symm_op(atomic_coord, symm_op)\n",
    "                    ## apply conversion from conventional to primitive basis\n",
    "                    ## convert the coordinates from conventional to primitive using the transform matrices\n",
    "                    ## defined from the qe convention. Note that the inverse of the transform matrix is used\n",
    "                    ## because coordinates transform inversely w.r.t. lattice vectors\n",
    "                    conventional, primitive = get_bravais_vectors(self.qe_parameters[\"ibrav\"], self.qe_parameters[\"alphar\"],\n",
    "                                self.qe_parameters[\"betar\"],self.qe_parameters[\"gammar\"])\n",
    "                    transform_matrix_prim_to_conv = conventional @ np.linalg.inv(primitive)\n",
    "                    eq_coord_prim = (transform_matrix_prim_to_conv.T @ np.asarray(eq_coord).T).T\n",
    "                    ## here the check for repetition is done already in the primitive cell\n",
    "                    ## if the position was not present, it is added to self.atomic_coord_list_extended\n",
    "                    check_and_add_position_primitive(eq_coord_prim, self.atomic_type_list[a_i], \n",
    "                    self.atomic_coord_list_extended, self.atomic_type_list_extended, \n",
    "                    primitive, threshold=self.threshold)\n",
    "            ##\n",
    "\n",
    "            self.qe_parameters[\"atomic_coordinates\"] = self.atomic_coord_list_extended\n",
    "            self.qe_parameters[\"atomic_coordinates_types\"] = self.atomic_type_list_extended\n",
    "            ## Number of atoms from composition\n",
    "            self.nat = len(self.atomic_coord_list_extended)\n",
    "            self.qe_parameters[\"nat\"] = int(self.nat)\n",
    "\n",
    "    ## Angles in radiants\n",
    "    def generate_cell_data(self):\n",
    "        ## Finding Bravais lattice and corresponding ibrav\n",
    "        lattice = find_lattice(self.qe_parameters[\"a\"], self.qe_parameters[\"b\"], self.qe_parameters[\"c\"], \n",
    "            self.qe_parameters[\"alpha\"], self.qe_parameters[\"beta\"], self.qe_parameters[\"gamma\"])\n",
    "        self.ibrav = find_ibrav(self.qe_parameters[\"HMsg\"], lattice)\n",
    "        ## Composition shenanigans\n",
    "        self.composition = Composition(\" \".join(self.qe_parameters[\"formula_sum\"]))\n",
    "        ## Number of type of atoms from composition\n",
    "        self.ntyp = len(self.composition.formula.split(\" \"))\n",
    "\n",
    "        self.qe_parameters[\"ibrav\"] = self.ibrav\n",
    "        self.qe_parameters[\"ntyp\"] = self.ntyp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs in input the name of the individuals file and saves it in a pandas df\n",
    "def read_individuals(individuals):\n",
    "    column_names = {0 : \"Generation\", 1 : \"ID\", 2 : \"GenMode\", \n",
    "    4 : 'A', 5 : 'B', 7 : \"enthalpy\", 10 : \"fitness\", 15 : \"spacegroup\"}\n",
    "\n",
    "    individuals = pd.read_csv(individuals, sep=\"\\s+\", header=None, skiprows=2,usecols=column_names)\n",
    "    individuals.rename(columns=column_names, inplace=True)\n",
    "    individuals.sort_values(\"fitness\", inplace=True)\n",
    "    return individuals\n",
    "\n",
    "#Needs in input the name of the file with all the poscars, the id of the structure to be extracted and the name of the output poscar\n",
    "def find_poscar(all_poscars, id):\n",
    "    end=-1\n",
    "    with open(all_poscars,'r') as file:\n",
    "        testo_input = file.readlines()              \n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('EA'+str(id)):   \n",
    "            init = i\n",
    "            simm=int(line[line.find(':')+1:])\n",
    "        if line.startswith('EA'+str(id+1)):\n",
    "            end = i-1\n",
    "            break\n",
    "    if end == -1:                            \n",
    "        end = len(testo_input)-1\n",
    "        \n",
    "    poscar_str=''\n",
    "    for i in range(end-init+1):\n",
    "        poscar_str+=testo_input[init+i]\n",
    "    return poscar_str\n",
    "\n",
    "#Needs df of Individuals, fitness treshold, file gatheredPoscars and return best non duplicated structures (with symm>75)\n",
    "def best_structures(individuals_df, fitness_upto, all_poscars):\n",
    "    fitness_gs = individuals_df['fitness'].iloc[0]\n",
    "    uniques = []\n",
    "    SGs=[]\n",
    "    structure_gs = Poscar.from_str(find_poscar(all_poscars, individuals_df['ID'].iloc[0]))\n",
    "    \n",
    "    if individuals_df['spacegroup'].iloc[0] > 75:# and individuals_df['spacegroup'].iloc[0] != 187:\n",
    "        uniques.append(structure_gs)\n",
    "        SGs.append(individuals_df['spacegroup'].iloc[0])\n",
    "\n",
    "    for i, line_individuals_df in individuals_df.iterrows():\n",
    "        if line_individuals_df['fitness'] - fitness_gs >= fitness_upto:\n",
    "            break\n",
    "        if line_individuals_df['spacegroup'] < 75:# or line_individuals_df['spacegroup'] == 187:\n",
    "            continue\n",
    "        new_structure = Poscar.from_str(find_poscar(all_poscars, line_individuals_df['ID']))\n",
    "\n",
    "        check_dupilcate = False\n",
    "        \n",
    "        if StructureMatcher(ltol = 1.0, stol = 1.0, angle_tol = 10, scale=True).fit(structure_gs.structure, new_structure.structure):\n",
    "            check_dupilcate = True \n",
    "        \n",
    "        for structure in uniques:\n",
    "            if StructureMatcher(ltol = 1.0, stol = 1.0, angle_tol = 10, scale=True).fit(structure.structure, new_structure.structure):\n",
    "                check_dupilcate = True\n",
    "        if not check_dupilcate:\n",
    "            uniques.append(new_structure)\n",
    "            SGs.append(line_individuals_df['spacegroup'])\n",
    "    return uniques, SGs\n",
    "\n",
    "#Needs in input the name of the poscar and the name of the cif in output     \n",
    "def poscar_to_cif(poscar, cif, symprec, angprec):\n",
    "    poscar = Poscar.from_str(poscar, read_velocities=True)\n",
    "    try:\n",
    "        cif_structure = CifWriter(poscar.structure, symprec=symprec, angle_tolerance=angprec)\n",
    "    except:\n",
    "        print(\"Pymatgen returned an error. Your symprec might be too large\")\n",
    "    cif_structure.write_file(cif)\n",
    "    return\n",
    "\n",
    "#Copy Individuals and gatheredPoscars files \n",
    "def copy_files(A, B):\n",
    "    dir_all_Individuals='./all_Individuals/'\n",
    "    dir_all_poscars='./all_poscars/'\n",
    "    shutil.copyfile(f'./OUTPUTFILES/{A+B}/{A+B}_gatheredPOSCARS', dir_all_poscars+f'{A+B}_gatheredPOSCARS')\n",
    "    shutil.copyfile(f'./OUTPUTFILES/{A+B}/{A+B}_Individuals', dir_all_Individuals+f'{A+B}_Individuals')\n",
    "    return\n",
    "\n",
    "#Take the poscar in str format and write the qe input\n",
    "def poscar_to_input(poscar, id, qe_input=qe_input):\n",
    "    dir_all_cif='./all_cif/'\n",
    "    dir_all_qeinput='./all_qeinput/'\n",
    "    poscar_to_cif(poscar, dir_all_cif + f'{id}.cif', 0.4, 5)\n",
    "    qe = PWSCf_input(qe_input, cifname=dir_all_cif + f'{id}.cif')\n",
    "    qe.read_cif()\n",
    "    qe.write_scf_input(qe_input_name=dir_all_qeinput+f'{id}.in')\n",
    "    return\n",
    "\n",
    "#Modify only the names of elements in atomic positions\n",
    "def modify_qe_atomic_positions(input, new_input, A, B):\n",
    "    old_el=[]\n",
    "    new_el=[A,B]\n",
    "    check = False\n",
    "    with open(input, 'r') as file:\n",
    "        testo_input=file.readlines()\n",
    "    \n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('ATOMIC_SPECIES'):\n",
    "            old_el.append(testo_input[i+1].split()[0])\n",
    "            old_el.append(testo_input[i+2].split()[0])\n",
    "        if line.startswith('K_POINTS'):\n",
    "            check = False\n",
    "        if check:\n",
    "            atom=line.split()[0]\n",
    "            testo_input[i]=line.replace(atom,new_el[old_el.index(atom)])\n",
    "        if line.startswith('ATOMIC_POSITIONS'):\n",
    "            check = True\n",
    "     \n",
    "    with open(new_input, 'w') as file:\n",
    "        file.writelines(testo_input)\n",
    "    return\n",
    "\n",
    "#Needs in input the name of the qe input, the species and their mass\n",
    "def modify_qe_input_element(template, qe_input, A, B, mA, mB):\n",
    "    with open(template, 'r') as file:\n",
    "            testo_input=file.readlines()\n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('  prefix'):\n",
    "            testo_input[i]=f'  prefix = \\'{A}{B}\\'\\n'            \n",
    "        if line.startswith('ATOMIC_SPECIES'):\n",
    "            testo_input[i+1]=f'{A} {mA} {A}_ONCV_PBE_sr.upf\\n'\n",
    "            testo_input[i+2]=f'{B} {mB} {B}_ONCV_PBE_sr.upf\\n'    \n",
    "            break\n",
    "    with open(qe_input, 'w') as file:\n",
    "            file.writelines(testo_input)\n",
    "    return\n",
    "\n",
    "\n",
    "#Setup the QE input using a template, celldm array, species A and B and their masses\n",
    "def setup_QEinput(input, new_input, A, B, mA, mB):\n",
    "    modify_qe_atomic_positions(input, new_input, A, B)\n",
    "    modify_qe_input_element(new_input, new_input, A, B, mA, mB) \n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "###--------MANAGE QUANTUM ESPRESSO I/O--------###\n",
    "\n",
    "#### RUN\n",
    "\n",
    "#Run pw.x in parallel using file input and output\n",
    "def run_pw(fileinput, fileoutput, nproc):\n",
    "    return\n",
    "    commmand=f'mpirun -np {nproc} -x OMP_NUM_THREADS=1 pw.x < ' + fileinput + '>' + fileoutput\n",
    "    set_elconvthr(fileinput, 1e-4)\n",
    "    os.system(commmand)\n",
    "    celldm_vec=find_celldm(fileoutput)\n",
    "    set_celldm(fileinput, celldm_vec)\n",
    "    set_elconvthr(fileinput, 1e-6)\n",
    "    os.system(commmand)\n",
    "    celldm_vec=find_celldm(fileoutput)\n",
    "    set_elconvthr(fileinput, 1e-8)\n",
    "    set_celldm(fileinput, celldm_vec)\n",
    "    os.system(commmand)\n",
    "    return\n",
    "\n",
    "#Check if the run is converged\n",
    "def check_convergence(file_output, n_fails, A, B):\n",
    "    return True\n",
    "    dir_all_qeoutput='./all_qeoutput/'\n",
    "\n",
    "    with open(dir_all_qeoutput + file_output, 'r') as file:\n",
    "        flag = False\n",
    "        for line in file:\n",
    "            if line.startswith('     Final scf calculation at the relaxed structure.'):\n",
    "                flag = True\n",
    "            if flag and line.startswith('     convergence has been achieved'):\n",
    "                return True\n",
    "            \n",
    "        create_directory('./NotConverged')\n",
    "        shutil.copyfile(dir_all_qeoutput + file_output, f'./NotConverged/{n_fails+1}_{A + B + file_output}')\n",
    "\n",
    "    return False\n",
    "\n",
    "#Set the celldm in the input file\n",
    "def set_celldm(fileinput, celldm_vec):\n",
    "\n",
    "    with open(fileinput, 'r') as file:\n",
    "        testo_input=file.readlines()\n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('   celldm(1)'):\n",
    "            testo_input[i]=f'   celldm(1) = {celldm_vec[0]}\\n'\n",
    "        if line.startswith('   celldm(2)'):\n",
    "            testo_input[i]=f'   celldm(2) = {celldm_vec[1]}\\n'\n",
    "        if line.startswith('   celldm(3)'):\n",
    "            testo_input[i]=f'   celldm(3) = {celldm_vec[2]}\\n'\n",
    "        if line.startswith('   celldm(4)'):\n",
    "            testo_input[i]=f'   celldm(4) = {celldm_vec[3]}\\n'\n",
    "        if line.startswith('   celldm(5)'):\n",
    "            testo_input[i]=f'   celldm(5) = {celldm_vec[4]}\\n'\n",
    "        if line.startswith('   celldm(6)'):\n",
    "            testo_input[i]=f'   celldm(6) = {celldm_vec[5]}\\n'\n",
    "    with open(fileinput, 'w') as file:\n",
    "        file.writelines(testo_input)\n",
    "    return\n",
    "\n",
    "#set the elconvthr in the input file\n",
    "def set_elconvthr(fileinput, elconvthr):\n",
    "\n",
    "    with open(fileinput, 'r') as file:\n",
    "        testo_input=file.readlines()\n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('   conv_thr'):\n",
    "            testo_input[i]=f'   conv_thr =  {elconvthr}\\n'\n",
    "    with open(fileinput, 'w') as file:\n",
    "        \n",
    "        file.writelines(testo_input)\n",
    "    return\n",
    "\n",
    "#Change the celldm1 in the input file in order to make more easy the vc relax\n",
    "def change_celldm1(file_input, A_old, B_old, A_new, B_new, comp): \n",
    "    A_old_r= float(Element(A_old).atomic_radius)\n",
    "    B_old_r= float(Element(B_old).atomic_radius)\n",
    "    A_new_r= float(Element(A_new).atomic_radius)\n",
    "    B_new_r= float(Element(B_new).atomic_radius)    \n",
    "\n",
    "    with open(file_input, 'r') as file:\n",
    "        testo_input=file.readlines()\n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('   celldm(1)'):\n",
    "            celldm_old=float(re.search(r'-?\\d+.\\d+',line).group())\n",
    "            celldm_new = celldm_old * (A_new_r * comp + B_new_r ) / ( A_old_r * comp +B_old_r )\n",
    "            testo_input[i]='   celldm(1) = ' + str(celldm_new) + ' \\n'\n",
    "            break\n",
    "    with open(file_input, 'w') as file:\n",
    "        file.writelines(testo_input)\n",
    "    return   \n",
    "\n",
    "\n",
    "#Needs output file of QE and return array of celldm\n",
    "def find_celldm(file_output):\n",
    "    celldm=np.full(6,0.0)\n",
    "    \n",
    "    with open(file_output, 'r') as file:\n",
    "        for line in file:                                               #find i valori di partenza dei celldm\n",
    "            if line.startswith('     celldm(1)'):\n",
    "                dm = (re.search(r'celldm\\(1\\)=\\s*-?\\d+.\\d+',line)).group()\n",
    "                celldm[0] = float(dm[dm.find('=') + 1 : ])\n",
    "\n",
    "                dm = (re.search(r'celldm\\(2\\)=\\s*-?\\d+.\\d+',line)).group()\n",
    "                celldm[1] = float(dm[dm.find('=') + 1 : ])\n",
    "                \n",
    "                dm = (re.search(r'celldm\\(3\\)=\\s*-?\\d+.\\d+',line)).group()\n",
    "                celldm[2] = float(dm[dm.find('=') + 1 : ])\n",
    "\n",
    "            if line.startswith('    celldm(4)'):\n",
    "                dm = (re.search(r'celldm\\(4\\)=\\s*-?\\d+.\\d+',line)).group()\n",
    "                celldm[3] = float(dm[dm.find('=') + 1 : ])\n",
    "\n",
    "                dm = (re.search(r'celldm\\(5\\)=\\s*-?\\d+.\\d+',line)).group()\n",
    "                celldm[4] = float(dm[dm.find('=') + 1 : ])\n",
    "\n",
    "                dm = (re.search(r'celldm\\(6\\)=\\s*-?\\d+.\\d+',line)).group()\n",
    "                celldm[5] = float(dm[dm.find('=') + 1 : ])                    \n",
    "                \n",
    "                break\n",
    "    with open(file_output, 'r') as file:\n",
    "        for i in file:   \n",
    "            if i.startswith(' celldm'):\n",
    "                dm = (re.search(r'celldm\\(\\d\\) =\\s*-?\\d+.\\d+',i)).group()\n",
    "                celldm[int(dm[7])-1] = float(dm[dm.find('=') + 1 : ])                \n",
    "    return celldm\n",
    "\n",
    "\n",
    "\n",
    "#Find enthalpy from output file of QE\n",
    "def find_enthalpy(file_output):\n",
    "    \n",
    "    with open(file_output, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('     Final enthalpy'):\n",
    "                enthalpy = re.search(r'-?\\d+.\\d+',line[line.find('=')+1:])\n",
    "\n",
    "    return float(enthalpy.group())*13.6\n",
    "\n",
    "#Find natm from output file of QE\n",
    "def find_natm(file_output):\n",
    "\n",
    "    with open(file_output, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('     number of atoms/cell'):\n",
    "                natm = re.search(r'\\d+',line[line.find('='):])\n",
    "                break\n",
    "          \n",
    "    return float(natm.group())\n",
    "\n",
    "\n",
    "\n",
    "#Find element type in the qe input file (for change in celldm1)\n",
    "def find_element_type(file_input):\n",
    "    with open(file_input) as file:\n",
    "        testo_input = file.readlines()\n",
    "\n",
    "    for i, line in enumerate(testo_input):\n",
    "        if line.startswith('ATOMIC_SPECIES'):\n",
    "            A = testo_input[i+1].split()[0]\n",
    "            B = testo_input[i+2].split()[0]\n",
    "            break\n",
    "    return A, B\n",
    "\n",
    "#Find Enthalpy from previous relaxed\n",
    "\n",
    "def find_enthalpy_relaxed(df, gen_couple, rel_couple, sg):\n",
    "    try:\n",
    "        enthalpy = df.loc[rel_couple, f'{gen_couple}_{sg}']\n",
    "    except Exception as e:\n",
    "        print(f\"Si Ã¨ verificato un errore: {e}\")\n",
    "        return None\n",
    "    return enthalpy\n",
    "\n",
    "####----------------------------MANAGE FILE FUNCTIONS---------------------------------####\n",
    "\n",
    "#Remove the file\n",
    "def remove_file(file):\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "    return\n",
    "\n",
    "#Remove the directory\n",
    "def remove_directory(directory):\n",
    "    if os.path.exists(directory):\n",
    "        subprocess.run(['rm', '-r', directory])        \n",
    "    return\n",
    "\n",
    "#Create the directory\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "###-----------------MANAGE TEMPLATES-----------------###\n",
    "\n",
    "# Compute the Levenshtein distance between two arrays\n",
    "def levensthein_distance(a1,a2):\n",
    "    dist=0\n",
    "    for i in range(len(a1)):\n",
    "        if a1[i] != a2[i]:\n",
    "            dist+=1-float(i)/len(a1)\n",
    "    return dist\n",
    "\n",
    "class TemplateSet:\n",
    "    def __init__(self, file = None, comp = 1 ):\n",
    "        self.dir_all_Individuals = './all_Individuals/'\n",
    "        self.dir_all_poscars = './all_poscars/'\n",
    "        self.dir_all_qeoutput = './all_qeoutput/'\n",
    "        self.dir_all_qeinput = './all_qeinput/'\n",
    "        self.dir_all_cif = './all_cif/'\n",
    "        create_directory(self.dir_all_cif)\n",
    "        create_directory(self.dir_all_Individuals)\n",
    "        create_directory(self.dir_all_poscars)\n",
    "        create_directory(self.dir_all_qeoutput)\n",
    "        create_directory(self.dir_all_qeinput)\n",
    "\n",
    "        self.gen_couples = [['B','Be'],['Be','O'],['B','Li'], ['B','N'], ['Mg','O'], ['C','Li'], ['C','N'], ['Li','Mg'], ['B','C'], ['N','O'], ['Li','N'], ['Mg','Na'], ['Li','Na'],['Mg','N'],['Li','O']]\n",
    "\n",
    "        self.df = pd.read_csv('./AB_relaxation/RELAX_DATA', sep=\",\", index_col=0)\n",
    "\n",
    "        self.count_flag = 1\n",
    "        self.comp = comp\n",
    "        self.num_template = 0\n",
    "        self.n_fails = 0\n",
    "        \n",
    "        self.couples = [] #Couples chosen for the templates\n",
    "        self.banned_couples = [] #Couples with no available templates (Already  chosen or non existent)\n",
    "        self.spacegroups = []\n",
    "        self.poscars = []\n",
    "        \n",
    "        self.from_scratch = True\n",
    "        self.flag_conv = True\n",
    "\n",
    "        self.trial_SG = None\n",
    "        self.trial_poscar = None\n",
    "        self.trial_couple = None\n",
    "        \n",
    "        if file is not None:\n",
    "            self.from_scratch = False\n",
    "            \n",
    "            flag_couples=False\n",
    "            flag_ent=False\n",
    "            flag_idx=False\n",
    "            flag_poscars=False\n",
    "            flag_ea=False\n",
    "            \n",
    "            with open(file, 'r') as input:\n",
    "                lines=input.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.startswith('NUMBER OF TEMPLATES'):\n",
    "                    self.num_template = int(re.search(r'\\d+',line).group())\n",
    "                    self.data = np.zeros((2, self.num_template, self.num_template))\n",
    "                if line.startswith('COMPOSITION'):\n",
    "                    self.comp= float(re.search(r'\\d+(.\\d+)?', line).group())\n",
    "                if flag_poscars:\n",
    "                    if line.startswith('EA'):\n",
    "                        if flag_ea:\n",
    "                            self.poscars.append(poscar_str)\n",
    "                        flag_ea = True\n",
    "                        poscar_str=''\n",
    "                    poscar_str+=line\n",
    "                if line.startswith('POSCARS'):\n",
    "                    flag_poscars = True\n",
    "                    flag_idx = False\n",
    "                if flag_idx:\n",
    "                    self.data[1,int(line[0])]=(np.array(line[line.find('[')+1:line.find(']')].split())).astype(float)  \n",
    "                if line.startswith('RANKING VECTORS IDX'):\n",
    "                    flag_idx = True\n",
    "                    flag_ent = False\n",
    "                if flag_ent:\n",
    "                    self.data[0,int(line[0])]=(np.array(line[line.find('[')+1:line.find(']')].split())).astype(float)\n",
    "                if line.startswith('RANKING VECTORS ENTHALPIES'):\n",
    "                    flag_ent = True\n",
    "                    flag_couples = False                    \n",
    "                if flag_couples:\n",
    "                    self.spacegroups.append(int(line[line.find(',')+1:]))\n",
    "                    self.couples.append(line[line.find('[')+1:line.find(']')].split())\n",
    "                if line.startswith('COUPLES'):\n",
    "                    flag_couples = True      \n",
    "            self.poscars.append(poscar_str)\n",
    "            \n",
    "            for i, poscar in enumerate(self.poscars):\n",
    "                poscar_to_input(poscar, i, qe_input=qe_input)\n",
    "        return\n",
    "    \n",
    "    def try_new_couple(self, test_elements):\n",
    "        self.trial_couple = None\n",
    "        self.trial_poscar = None\n",
    "        self.trial_SG = None\n",
    "        \n",
    "        while self.count_flag<11:\n",
    "            \n",
    "            extraction_list = [x for x in self.gen_couples if x not in self.banned_couples]\n",
    "            #causal_el = random.sample(test_elements, 2)\n",
    "            causal_el = random.sample(extraction_list,1)\n",
    "            causal_el = [x for y in causal_el for x in y]\n",
    "            causal_el.sort() ##to be commented for other compositions\n",
    "            \n",
    "            #elif causal_el not in self.couples:\n",
    "            A=causal_el[0]\n",
    "            B=causal_el[1]\n",
    "            \n",
    "            print(f'Trying generating new template with: {A+B} (Try #{self.count_flag})\\n')\n",
    "            self.count_flag+=1\n",
    "            copy_files(A, B)\n",
    "\n",
    "            df_individuals = read_individuals(self.dir_all_Individuals+f'{A+B}_Individuals')\n",
    "            P, SG = best_structures(df_individuals, 0.1, self.dir_all_poscars+f'{A+B}_gatheredPOSCARS')\n",
    "                \n",
    "            if len(SG) > 0:\n",
    "                print(f'There are {len(SG)} possible templates\\n')\n",
    "                self.trial_couple = causal_el\n",
    "                for k in range(len(SG)):\n",
    "                    if SG[k] not in self.spacegroups:\n",
    "                        self.trial_poscar = P[k]\n",
    "                        self.trial_SG = int(SG[k])\n",
    "                        break\n",
    "                if self.trial_SG is None:\n",
    "                    print(f'All possible templates simmetries are already chosen: {SG}\\n')\n",
    "                    for k in range(len(SG)):\n",
    "                        idx = [i for i, x in enumerate(self.spacegroups) if x == SG[k]]\n",
    "                        for l in idx:\n",
    "                            template_already_chosen = False\n",
    "                            if self.couples[l] == causal_el:\n",
    "                                print(f'The couple has been already chosen with the simmetry {SG[k]}\\n')\n",
    "                                template_already_chosen = True\n",
    "                                break\n",
    "                        if not template_already_chosen:\n",
    "                            self.trial_poscar = P[k]\n",
    "                            self.trial_SG = int(SG[k])\n",
    "                            break\n",
    "                if self.couples.count(causal_el) == len(SG)-1:\n",
    "                    print(f'All the structure near ground state have been already chosen: the couple {A+B} won\\'t be sorted again\\n')\n",
    "                    self.banned_couples.append(causal_el)\n",
    "                break   \n",
    "            else:\n",
    "                print(f'No structures with high simmetry near ground state: choosign new couple\\n')\n",
    "                self.banned_couples.append(causal_el)\n",
    "                continue\n",
    "        poscar_to_input(str(self.trial_poscar), self.num_template)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def make_ranking_vec(self):\n",
    "        self.flag_conv = True\n",
    "        new_ranking = np.zeros((2, self.num_template))  \n",
    "        A = self.trial_couple[0]\n",
    "        B = self.trial_couple[1]\n",
    "\n",
    "        for i in range(self.num_template):\n",
    "        \n",
    "            print(f'Running {i}-th relaxation for ranking vector for couple {A+B}\\n')\n",
    "            overwrite_A, overwrite_B = find_element_type(self.dir_all_qeinput+f'{i}.in')\n",
    "            change_celldm1(self.dir_all_qeinput+f'{i}.in', overwrite_A, overwrite_B, A , B, self.comp )\n",
    "        \n",
    "            setup_QEinput(self.dir_all_qeinput+f'{i}.in',self.dir_all_qeinput+f'{i}.in', str(Element(A)), str(Element(B)), float(Element(A).atomic_mass), float(Element(B).atomic_mass))\n",
    "            run_pw(self.dir_all_qeinput+f'{i}.in', self.dir_all_qeoutput+f'{i}.out', 4) \n",
    "        \n",
    "            self.flag_conv =  check_convergence(f'{i}.out', self.n_fails, A , B)\n",
    "            if not self.flag_conv:\n",
    "                print(f'WARNING: {i}-th relaxation did not converge, skipped the couple {A+B}\\n')\n",
    "                self.n_fail+=1\n",
    "                if self.trial_couple not in self.banned_couples:\n",
    "                    self.banned_couples.append(self.trial_couple)\n",
    "                new_ranking[:]=-1\n",
    "                break\n",
    "\n",
    "            if self.flag_conv:\n",
    "                new_ranking[0,i]= find_enthalpy_relaxed(self.df,f'{self.couples[i][0]+self.couples[i][1]}', f'{self.trial_couple[0]+self.trial_couple[1]}', self.spacegroups[i]) #find_enthalpy(self.dir_all_qeoutput+f'{i}.out')/find_natm(self.dir_all_qeoutput+f'{i}.out')                                           \n",
    "                new_ranking[1,i] = int(i)    \n",
    "                new_ranking = new_ranking[:, new_ranking[0].argsort()]   \n",
    "        \n",
    "        return new_ranking\n",
    "    \n",
    "    def own_relax(self, ranking_vec = np.array([[],[]]) ):\n",
    "        A = self.trial_couple[0]\n",
    "        B = self.trial_couple[1]\n",
    "\n",
    "        print('Running relaxation on own template...\\n')\n",
    "        setup_QEinput(self.dir_all_qeinput+f'{self.num_template}.in',self.dir_all_qeinput+f'{self.num_template}.in', str(Element(A)), str(Element(B)), float(Element(A).atomic_mass), float(Element(B).atomic_mass))\n",
    "        run_pw(self.dir_all_qeinput+f'{self.num_template}.in', self.dir_all_qeoutput+f'{self.num_template}.out', 4)\n",
    "        new_fitness= find_enthalpy_relaxed(self.df,f'{self.trial_couple[0]+self.trial_couple[1]}', f'{self.trial_couple[0]+self.trial_couple[1]}', self.trial_SG) #find_enthalpy(self.dir_all_qeoutput+f'{self.num_template}.out')/find_natm(self.dir_all_qeoutput+f'{self.num_template}.out')\n",
    "        new_ranking = np.append(ranking_vec, [[new_fitness], [self.num_template]], axis=1)\n",
    "\n",
    "        if self.num_template == 0:\n",
    "            self.data = np.zeros((2,1,1))\n",
    "            self.data[0] = new_ranking[0]\n",
    "            self.data[1] = new_ranking[1]\n",
    "\n",
    "        return new_ranking\n",
    "\n",
    "    def relax_on_new_template(self):\n",
    "        self.flag_conv = True\n",
    "        couples = self.couples\n",
    "        num_template = self.num_template\n",
    "\n",
    "        new_column = np.zeros(num_template)\n",
    "        for i, couple in enumerate(couples):\n",
    "            print(f'Running relaxation on new template for the {i}-th couple...\\n')\n",
    "            overwrite_A, overwrite_B = find_element_type(self.dir_all_qeinput+f'{num_template}.in')\n",
    "            change_celldm1(self.dir_all_qeinput+f'{num_template}.in', overwrite_A, overwrite_B, str(Element(couple[0])) , str(Element(couple[1])), self.comp)\n",
    "            setup_QEinput(self.dir_all_qeinput+f'{num_template}.in',self.dir_all_qeinput+f'{num_template}.in', str(Element(couple[0])), str(Element(couple[1])), float(Element(couple[0]).atomic_mass), float(Element(couple[1]).atomic_mass))\n",
    "            run_pw(self.dir_all_qeinput+f'{num_template}.in', self.dir_all_qeoutput+f'{num_template}.out', 4)\n",
    "            self.flag_conv =  check_convergence(f'{num_template}.out', self.n_fails, self.trial_couple[0] , self.trial_couple[1])\n",
    "\n",
    "            if not self.flag_conv:\n",
    "                print(f'WARNING: {i}-th relaxation did not converge, skipped the couple {self.trial_couple[0]+self.trial_couple[1]}\\n')\n",
    "                new_column[:] = -1\n",
    "                self.n_fails+=1\n",
    "                if self.trial_couple not in self.banned_couples:\n",
    "                    self.banned_couples.append(self.trial_couple)\n",
    "                break\n",
    "            if self.flag_conv:\n",
    "                new_column[i] = find_enthalpy_relaxed(self.df,f'{self.trial_couple[0]+self.trial_couple[1]}', f'{couple[0]+couple[1]}', self.trial_SG) #find_enthalpy(self.dir_all_qeoutput+f'{num_template}.out')/find_natm(self.dir_all_qeoutput+f'{num_template}.out')\n",
    "        if self.flag_conv:\n",
    "            self.add_column(new_column)\n",
    "        return new_column\n",
    "\n",
    "    def add_column(self, column_values):\n",
    "        # Add new column to the end of each matrix\n",
    "        idx_column = np.full((self.data.shape[1]),self.num_template)\n",
    "        self.data = np.pad(self.data, ((0, 0), (0, 0), (0, 1)), constant_values=0)\n",
    "        self.data[0,:,-1] = column_values\n",
    "        self.data[1,:,-1] = idx_column\n",
    "        return\n",
    "\n",
    "    def add_row(self, row_values, idx_row):\n",
    "        # Add new row to the end of each matrix\n",
    "        self.data = np.pad(self.data, ((0, 0), (0, 1), (0, 0)), constant_values=0)\n",
    "        self.data[0,-1,:] = row_values\n",
    "        self.data[1,-1,:] = idx_row\n",
    "        return\n",
    "    \n",
    "    def order(self):\n",
    "        # Order the matrix by rows of first matrix\n",
    "        sorted_indices = np.argsort(self.data[0], axis=1)\n",
    "        for i in range(self.data.shape[1]):\n",
    "            self.data[0,i] = self.data[0,i, sorted_indices[i]]\n",
    "            self.data[1,i] = self.data[1,i, sorted_indices[i]]\n",
    "        return\n",
    "    \n",
    "    def distance(self, array):\n",
    "        # Compute the Levenshtein distance between the rows of the first matrix and the array\n",
    "        lev = np.zeros(self.data.shape[1])\n",
    "        for i in range(self.data.shape[1]):\n",
    "            lev[i] = levensthein_distance(self.data[1,i], array)\n",
    "        return lev\n",
    "\n",
    "    def update(self):\n",
    "        self.couples.append(self.trial_couple)\n",
    "        self.spacegroups.append(self.trial_SG)\n",
    "        self.poscars.append(self.trial_poscar)\n",
    "        self.num_template += 1\n",
    "        self.order()\n",
    "        self.count_flag = 1\n",
    "        return \n",
    "    \n",
    "    def print_file(self, file = None):\n",
    "        if file is not None:\n",
    "            relax_file = file\n",
    "        else:\n",
    "            relax_file = f'TemplateSet_{self.comp}'\n",
    "        with open(relax_file, 'w') as file:\n",
    "            file.write(f'NUMBER OF TEMPLATES {self.num_template}\\n')\n",
    "            file.write(f'COMPOSITION A {self.comp} B\\n')\n",
    "            file.write('COUPLES , SPACEGROUPS \\n')\n",
    "            for i, couple in enumerate(self.couples):\n",
    "                file.write(f'[{couple[0]} {couple[1]}] , {self.spacegroups[i]} \\n')    \n",
    "            file.write('RANKING VECTORS ENTHALPIES\\n')\n",
    "            for i, vec in enumerate(self.data[0]):\n",
    "                arr = str(vec).replace('\\n','')\n",
    "                file.write(f'{i}:{arr} \\n')\n",
    "            file.write('RANKING VECTORS IDX\\n')\n",
    "            for i, vec in enumerate(self.data[1]):\n",
    "                arr = str(vec).replace('\\n','')\n",
    "                file.write(f'{i}:{arr} \\n')  \n",
    "            file.write('POSCARS\\n')\n",
    "            for i in self.poscars:\n",
    "                file.write(str(i))\n",
    "        return\n",
    "    \n",
    "class PairSet:\n",
    "    def __init__(self, template_set, test_elements, relaxed_pairs = None, comp=1 ) -> None:\n",
    "        \n",
    "        #DA METTERE INDIPENDENZA DA TEMPLATE SET\n",
    "        self.test_elements=test_elements\n",
    "        self.from_scratch = True   \n",
    "        self.num_pairs = 0\n",
    "        self.n_fails = 0\n",
    "        self.num_template = template_set.num_template\n",
    "        self.comp = template_set.comp\n",
    "\n",
    "        self.couples = []\n",
    "        self.banned_couples = []\n",
    "        self.poscars = template_set.poscars\n",
    "        self.sg = template_set.spacegroups\n",
    "        self.gen_couples = template_set.couples  \n",
    "        self.data = np.zeros((3, self.num_template, self.num_pairs))\n",
    "\n",
    "        self.dir_all_cif = './all_cif/'\n",
    "        self.dir_all_qeoutput = './all_qeoutput/'\n",
    "        self.dir_all_qeinput = './all_qeinput/'\n",
    "        create_directory(self.dir_all_cif)\n",
    "        create_directory(self.dir_all_qeoutput)\n",
    "        create_directory(self.dir_all_qeinput)\n",
    "\n",
    "        self.df = pd.read_csv('./AB_relaxation/RELAX_DATA', sep=\",\", index_col=0)\n",
    "        self.one_el = pd.read_csv('./AB_relaxation/OneElementEnt.txt', sep=',', header=None)\n",
    "        self.gs_df = pd.read_csv('./AB_relaxation/GroundStates.txt', sep=\",\")\n",
    "\n",
    "        \n",
    "        if relaxed_pairs is not None:\n",
    "            self.from_scratch = False\n",
    "\n",
    "            flag_couples=False\n",
    "            flag_ent=False\n",
    "            flag_idx_2=False\n",
    "            flag_idx=False\n",
    "\n",
    "            with open(relaxed_pairs, 'r') as input:\n",
    "                lines=input.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.startswith('NUMBER OF PAIRS'):\n",
    "                    self.num_pairs= int(re.search(r'\\d+', line).group())\n",
    "                    self.data = np.zeros((3, self.num_template, self.num_pairs))\n",
    "                if flag_idx_2:\n",
    "                    self.data[2,int(line[0])]=(np.array(line[line.find('[')+1:line.find(']')].split())).astype(float)  \n",
    "                if line.startswith('R(P) IDX'):\n",
    "                    flag_idx_2 = True\n",
    "                    flag_idx = False\n",
    "                if flag_idx:\n",
    "                    self.data[1,int(line[0])]=(np.array(line[line.find('[')+1:line.find(']')].split())).astype(float)  \n",
    "                if line.startswith('R(T) IDX'):\n",
    "                    flag_idx = True\n",
    "                    flag_ent = False\n",
    "                if flag_ent:\n",
    "                    self.data[0,int(line[0])]=(np.array(line[line.find('[')+1:line.find(']')].split())).astype(float)\n",
    "                if line.startswith('RANKING VECTORS ENTHALPIES'):\n",
    "                    flag_ent = True\n",
    "                    flag_couples = False                    \n",
    "                if flag_couples:\n",
    "                    self.couples.append(line[line.find('[')+1:line.find(']')].split())\n",
    "                if line.startswith('RELAXED COUPLES'):\n",
    "                    flag_couples = True      \n",
    "        pass\n",
    "\n",
    "    def add_pair(self):\n",
    "        tries=0\n",
    "        while True:\n",
    "            if tries>=5:\n",
    "                print('WARNING: too many tries, no new pair added\\n')\n",
    "                return\n",
    "            tries+=1\n",
    "            while True:\n",
    "                causal_el = random.sample(self.test_elements, 2)\n",
    "                causal_el.sort() ##to be commented for other compositions\n",
    "                if causal_el in self.banned_couples:\n",
    "                    continue\n",
    "                elif causal_el not in self.couples:\n",
    "                    A=causal_el[0]\n",
    "                    B=causal_el[1]\n",
    "                    break\n",
    "            print(f'Trying add to set the couple {A+B} (Try#{tries})\\n')\n",
    "\n",
    "            new_ranking = np.zeros(self.num_template)\n",
    "            for i in range(self.num_template):\n",
    "                print(f'Running relaxation on {i}-th template with couple {A+B}\\n')\n",
    "                overwrite_A, overwrite_B = find_element_type(self.dir_all_qeinput+f'{i}.in')\n",
    "                change_celldm1(self.dir_all_qeinput+f'{i}.in', overwrite_A, overwrite_B, A , B, self.comp)\n",
    "                setup_QEinput(self.dir_all_qeinput+f'{i}.in',self.dir_all_qeinput+f'{i}.in', str(Element(A)), str(Element(B)), float(Element(A).atomic_mass), float(Element(B).atomic_mass))\n",
    "                run_pw(self.dir_all_qeinput+f'{i}.in', self.dir_all_qeoutput+f'{i}.out', 4)\n",
    "            \n",
    "                convergence_flag =  check_convergence(f'{i}.out', self.n_fails, A , B)\n",
    "                if not convergence_flag:\n",
    "                    print(f'WARNING: relaxation did not converge, skipped the couple {A+B}\\n')\n",
    "                    self.n_fails+=1\n",
    "                    self.banned_couples.append([A,B])\n",
    "                    break\n",
    "                ent_form =  ( (self.one_el.loc[self.one_el[0] == f'{A}'].iloc[0,1]) * self.comp + (self.one_el.loc[self.one_el[0] == f'{B}'].iloc[0,1]) ) / (self.comp + 1 )\n",
    "                new_ranking[i] = find_enthalpy_relaxed(self.df,f'{self.gen_couples[i][0]+self.gen_couples[i][1]}', f'{A+B}', self.sg[i]) - ent_form #new_ranking[i] = find_enthalpy(self.dir_all_qeoutput+f'{i}.out')/find_natm(self.dir_all_qeoutput+f'{i}.out') -ent_form\n",
    "            if not convergence_flag:\n",
    "                print('WARNING: Too many failed relaxations exiting...\\n')\n",
    "                return\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        self.data = np.pad(self.data, ((0, 0), (0, 0), (0, 1)), constant_values=0)\n",
    "        self.data[0,:,-1] = new_ranking\n",
    "        self.data[1,:,-1] = self.num_pairs\n",
    "        self.data[2,:,-1] = np.arange(0, self.num_template, 1)\n",
    "        self.couples.append([A,B])\n",
    "        self.num_pairs += 1\n",
    "        return\n",
    "    \n",
    "    def print_relaxed_pairs(self, file_print = 'RelaxedPairs.txt'):\n",
    "        with open(file_print, 'w') as file:\n",
    "            file.write(f'NUMBER OF PAIRS {self.num_pairs}\\n')\n",
    "            file.write(f'COMPOSITION A {self.comp} B\\n')\n",
    "            file.write(f'NUMBER OF TEMPLATES {self.num_template}\\n')\n",
    "            file.write('RELAXED COUPLES\\n')\n",
    "            for i, couple in enumerate(self.couples):\n",
    "                file.write(f'[{couple[0]} {couple[1]}] \\n')  \n",
    "            file.write('RANKING VECTORS ENTHALPIES\\n')\n",
    "            for i in range(self.num_template):\n",
    "                arr = str(self.data[0,i]).replace('\\n','')\n",
    "                file.write(f'{i}:{arr} \\n')\n",
    "            file.write('R(T) IDX\\n')\n",
    "            for i in range(self.num_template):\n",
    "                arr = str(self.data[1,i]).replace('\\n','')\n",
    "                file.write(f'{i}:{arr} \\n')\n",
    "            file.write('R(P) IDX\\n')\n",
    "            for i in range(self.num_template):\n",
    "                arr = str(self.data[2,i]).replace('\\n','')\n",
    "                file.write(f'{i}:{arr} \\n')\n",
    "        return\n",
    "\n",
    "    def order_wrt_pairs(self):\n",
    "        # Order the matrix by rows of first matrix\n",
    "        matrix = self.data.copy()\n",
    "        sorted_indices = np.argsort(matrix[0], axis=1)\n",
    "        for i in range(matrix.shape[1]):\n",
    "            matrix[0,i] = matrix[0,i, sorted_indices[i]]\n",
    "            matrix[1,i] = matrix[1,i, sorted_indices[i]]\n",
    "            matrix[2,i] = matrix[2,i, sorted_indices[i]]\n",
    "        return matrix\n",
    "\n",
    "    def order_wrt_templates(self):\n",
    "        # Oreder the matrix by columns of first matrix\n",
    "        matrix = self.data.copy()\n",
    "        matrix = matrix.transpose((0,2,1))\n",
    "        sorted_indices = np.argsort(matrix[0], axis=1)\n",
    "        for i in range(matrix.shape[1]):\n",
    "            matrix[0,i] = matrix[0,i, sorted_indices[i]]\n",
    "            matrix[1,i] = matrix[1,i, sorted_indices[i]]\n",
    "            matrix[2,i] = matrix[2,i, sorted_indices[i]]\n",
    "        matrix = matrix.transpose((0,2,1))\n",
    "        return matrix\n",
    "\n",
    "    def dist_matrix(self):\n",
    "        # Compute the distance matrix between the templates moving the pairs\n",
    "        dist = np.zeros((self.num_template, self.num_template))\n",
    "        matrix = self.order_wrt_pairs()\n",
    "        for i in range(self.num_template):\n",
    "            for j in range(self.num_template):\n",
    "                dist[i,j] = levensthein_distance(matrix[1,i], matrix[1,j])*2/(self.num_pairs+1)\n",
    "        return dist\n",
    "    \n",
    "    def make_input(self):\n",
    "        # Make the input files for each template\n",
    "        for i in range(self.num_template):\n",
    "            poscar_to_input(str(self.poscars[i]), i, qe_input=qe_input)\n",
    "\n",
    "    def template_gs(self):\n",
    "        # Compute how many times each template is the ground state\n",
    "        ist = np.zeros(self.num_template)\n",
    "        matrix = self.order_wrt_templates()\n",
    "        for i in range(self.num_pairs):\n",
    "            idx = int(matrix[2,0,i])\n",
    "            ist [idx] += 1\n",
    "        return ist\n",
    "    \n",
    "    def formation_percentage(self):\n",
    "        # Compute the fraction of negative formation enthalpy for each template\n",
    "        form_negative = np.zeros(self.num_template)\n",
    "        for i in range(self.num_template):\n",
    "            form_negative[i] = np.sum(self.data[0,i] < 0)/self.num_pairs\n",
    "        return form_negative\n",
    "\n",
    "    def reduced_set(self, hyperparameters):\n",
    "        # Compute the reduced set of templates\n",
    "        form_negative = self.formation_percentage()\n",
    "        ist = self.template_gs()\n",
    "\n",
    "        set_of_templates = [x for x in range(self.num_template)]\n",
    "        set_of_removed_templates = []\n",
    "        lev_matrix = self.dist_matrix()\n",
    "\n",
    "        for i in range(self.num_template):\n",
    "            if set_of_templates[i] in set_of_removed_templates:\n",
    "                continue\n",
    "            for j in range(i+1,self.num_template):\n",
    "                if set_of_templates[j] in set_of_removed_templates:\n",
    "                    continue\n",
    "                if lev_matrix[i,j] < hyperparameters['lev_red']:\n",
    "                    a_j = form_negative[j] * hyperparameters['weight_formation_entalphy'] \n",
    "                    b_j = ist[j] * hyperparameters['weight_occurrence']/self.num_pairs\n",
    "                    c_j = self.sg[j] * hyperparameters['weight_sg']\n",
    "\n",
    "                    a_i = form_negative[i] * hyperparameters['weight_formation_entalphy']\n",
    "                    b_i = ist[i] * hyperparameters['weight_occurrence']/self.num_pairs\n",
    "                    c_i = self.sg[i] * hyperparameters['weight_sg']\n",
    "\n",
    "                    score_j = form_negative[j] * hyperparameters['weight_formation_entalphy'] + ist[j] * hyperparameters['weight_occurrence']/self.num_pairs + self.sg[j] * hyperparameters['weight_sg']\n",
    "                    score_i = form_negative[i] * hyperparameters['weight_formation_entalphy'] + ist[i] * hyperparameters['weight_occurrence']/self.num_pairs + self.sg[i] * hyperparameters['weight_sg']\n",
    "                    print(self.gen_couples[j], self.sg[j], a_j, b_j, c_j)\n",
    "                    print(self.gen_couples[i], self.sg[i], a_i, b_i, c_i)\n",
    "                    print(score_j, score_i)\n",
    "                    \n",
    "                    if score_j > score_i:\n",
    "                        set_of_removed_templates.append(set_of_templates[i])\n",
    "                        break\n",
    "                    else:\n",
    "                        set_of_removed_templates.append(set_of_templates[j])\n",
    "\n",
    "\n",
    "        return [x for x in set_of_templates if x not in set_of_removed_templates]\n",
    "\n",
    "    def error_single_composition(self, hyperparameters):\n",
    "        # Compute the error of the single composition\n",
    "        differences = []\n",
    "        set_of_remaining_templates = self.reduced_set(hyperparameters)\n",
    "        for k in range(len(self.test_elements)):\n",
    "            for l in range(k+1,len(self.test_elements)):\n",
    "                cp = [self.test_elements[k], self.test_elements[l]]\n",
    "                cp.sort()\n",
    "                try_couple = cp[0]+cp[1]\n",
    "\n",
    "                ent_gs = (self.gs_df.loc[self.gs_df['COUPLES'] == try_couple].iloc[0,1]) #already per atom  \n",
    "                ent_temp = np.zeros(len(set_of_remaining_templates))\n",
    "                for j, i in enumerate(set_of_remaining_templates):\n",
    "                    ent_temp[j] = self.df.loc[try_couple, f'{self.gen_couples[i][0]}{self.gen_couples[i][1]}_{self.sg[i]}'] #already per atom\n",
    "                ent_temp.sort()\n",
    "                differences.append( -( ent_gs - ent_temp[0] )) \n",
    "        return differences\n",
    "\n",
    "    def total_error(self, hyperparameters):\n",
    "        # Compute the total error of the reduced set\n",
    "        differences = self.error_single_composition(hyperparameters)\n",
    "        err = 0\n",
    "        for i in differences:\n",
    "            err += abs(i)\n",
    "        return err\n",
    "        \n",
    "\n",
    "def ent_single_elemet(file):\n",
    "    df = pd.read_csv(file, sep=',', header=None)\n",
    "    return df          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_templateset(hyperparameters, test_elements):\n",
    "    template = TemplateSet()\n",
    "\n",
    "    if template.from_scratch:\n",
    "        template.try_new_couple(test_elements)\n",
    "        template.own_relax()\n",
    "        template.update()\n",
    "        print(f'Class set inizialized: \\n{template.data}\\n')\n",
    "\n",
    "    while template.num_template < hyperparameters['n_template']:\n",
    "        template.try_new_couple(test_elements)\n",
    "        vec = template.make_ranking_vec()\n",
    "        lev_dist = template.distance(vec[1])*2/(template.num_template+1)\n",
    "        print(f'Levenshtein distance: {lev_dist}\\n')\n",
    "\n",
    "        if np.all(lev_dist < hyperparameters[\"lev_gen\"]) and template.num_template > 5:\n",
    "            print('Levensthein distance too low, trying new couple \\n')\n",
    "            continue\n",
    "\n",
    "        vec = template.own_relax(vec)\n",
    "        if not template.flag_conv:\n",
    "            continue\n",
    "\n",
    "        col = template.relax_on_new_template()\n",
    "        if not template.flag_conv:\n",
    "            continue\n",
    "\n",
    "        template.add_row(*vec)\n",
    "        template.update()\n",
    "    return template\n",
    "\n",
    "def generate_one_pairset (template_prod, hyperparameters, test_elements):\n",
    "    reduction_set = PairSet(template_prod, test_elements)\n",
    "    reduction_set.make_input()\n",
    "\n",
    "    while reduction_set.num_pairs < hyperparameters['n_pairs']:\n",
    "        reduction_set.add_pair()\n",
    "    create_directory(f'./TemplateSets/{template_prod.num_template}')\n",
    "    reduction_set.print_relaxed_pairs(f'./TemplateSets/{template_prod.num_template}/PairSet_{template_prod.num_template}')\n",
    "\n",
    "    return reduction_set\n",
    "\n",
    "#TICK SETINGS\n",
    "def graph_formation_and_occurrence(reduction_set):\n",
    "    ticks=np.array([])\n",
    "    for i in range(reduction_set.num_template):\n",
    "        ticks = np.append(ticks,f'{reduction_set.gen_couples[i][0]+reduction_set.gen_couples[i][1]}_{reduction_set.sg[i]}')\n",
    "\n",
    "    fig, axs = plt.subplots(1,2, figsize=(20,5))\n",
    "    ist = reduction_set.template_gs()\n",
    "    axs[0].bar(np.arange(0,reduction_set.num_template,1), ist, color = 'green', alpha=0.8, edgecolor='black')\n",
    "    axs[0].set_title('Number of ground state structures for each template')\n",
    "\n",
    "    form_negative = reduction_set.formation_percentage()\n",
    "    axs[1].bar(np.arange(0,reduction_set.num_template,1),form_negative, color='crimson', edgecolor='black')\n",
    "    axs[1].bar(np.arange(0,reduction_set.num_template,1),1, color='grey', zorder=0, alpha=0.8, edgecolor='black')\n",
    "    axs[1].set_title('Fraction of negative formation energies for each template')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks(np.arange(0,reduction_set.num_template,1))\n",
    "        ax.set_xticklabels(ticks)\n",
    "        ax.grid(axis='y', linestyle=':')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    cartella = '/home/seraf/PRESENTATION/'\n",
    "    nome_file = 'Occurrence_FormEnt.png'\n",
    "    percorso_completo = os.path.join(cartella, nome_file)\n",
    "    fig.savefig(percorso_completo)\n",
    "    return\n",
    "\n",
    "def graph_lev_matrix(reduction_set):\n",
    "    ticks=np.array([])\n",
    "    for i in range(reduction_set.num_template):\n",
    "        ticks = np.append(ticks,f'{reduction_set.gen_couples[i][0]+reduction_set.gen_couples[i][1]}_{reduction_set.sg[i]}')\n",
    "    lev_matrix = reduction_set.dist_matrix()\n",
    "\n",
    "    fig ,  ax = plt.subplots(1,2,figsize=(20,8))\n",
    "    sns.heatmap(lev_matrix, cmap='plasma', ax=ax[0])\n",
    "    #rect = Rectangle((54, 54),10, 10, fill=False, color='blue', lw=3)\n",
    "    #ax[0].add_patch(rect)\n",
    "    ax[0].set_xticklabels(ticks)\n",
    "    ax[0].set_yticklabels(ticks)\n",
    "    ax[0].set_title('Levenshtein distance matrix between r(T)')\n",
    "\n",
    "    Z = linkage(lev_matrix, method='average')\n",
    "    dn = dendrogram(Z, no_plot=True)\n",
    "    order = dn['leaves']\n",
    "    matrix_reordered = lev_matrix[order,:][:,order]\n",
    "    ticks = ticks[order]\n",
    "\n",
    "    sns.heatmap(matrix_reordered, cmap='plasma', ax=ax[1])\n",
    "    ax[1].set_xticklabels(ticks)\n",
    "    ax[1].set_yticklabels(ticks)\n",
    "    ax[1].set_title('Levenshtein distance matrix between r(T), reordered')\n",
    "\n",
    "    for axs in ax:\n",
    "        axs.tick_params(rotation=45)\n",
    "        axs.invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    cartella = '/home/seraf/PRESENTATION/'\n",
    "    nome_file = 'LevMatrices.png'\n",
    "    percorso_completo = os.path.join(cartella, nome_file)\n",
    "    fig.savefig(percorso_completo)\n",
    "    return\n",
    "\n",
    "def graph_reducted_set(reduction_set):\n",
    "    lev_matrix = reduction_set.dist_matrix()\n",
    "    set_of_remaining_templates = reduction_set.reduced_set(hyperparameters)\n",
    "    new_lev_matrix = np.zeros((len(set_of_remaining_templates), len(set_of_remaining_templates)))\n",
    "    for i in range(len(set_of_remaining_templates)):\n",
    "        for j in range(len(set_of_remaining_templates)):\n",
    "            new_lev_matrix[i,j] = lev_matrix[set_of_remaining_templates[i], set_of_remaining_templates[j]]\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1])\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "\n",
    "    ticks=[]\n",
    "    for i in set_of_remaining_templates:\n",
    "        ticks.append(f'{reduction_set.gen_couples[i][0]}{reduction_set.gen_couples[i][1]}_{reduction_set.sg[i]}')\n",
    "\n",
    "    sns.heatmap(new_lev_matrix, cmap='plasma', ax=ax0)\n",
    "\n",
    "    ax0.set_xticklabels(ticks)\n",
    "    ax0.set_yticklabels(ticks)\n",
    "    ax0.set_title('Levenshtein distance matrix between r(T), after reduction')\n",
    "    ax0.tick_params(rotation=45)\n",
    "    ax0.invert_yaxis()\n",
    "\n",
    "    differences = reduction_set.error_single_composition(hyperparameters)\n",
    "    ax1.barh(np.arange(0,len(differences),1), differences, color='green', edgecolor='black')\n",
    "    ax1.set_title(r'$\\Delta H$ for each couple')\n",
    "    ax1.set_yticks(np.arange(0,len(differences),1))\n",
    "    ax1.set_yticklabels([f'{test_elements[k]}{test_elements[l]}' for k in range(len(test_elements)) for l in range(k+1, len(test_elements))])\n",
    "    #ax.tick_params(axis='x', rotation=90)\n",
    "    ax1.grid(axis='x', linestyle=':')\n",
    "    ax1.set_xlabel('Enthalpy difference (eV/atom)')\n",
    "    #ax1.set_xlim(-2, 2)\n",
    "    plt.show()\n",
    "\n",
    "    cartella = '/home/seraf/PRESENTATION/'\n",
    "    nome_file = 'ReducedSet_stats.png'\n",
    "\n",
    "    percorso_completo = os.path.join(cartella, nome_file)\n",
    "    fig.savefig(percorso_completo)\n",
    "    return\n",
    "\n",
    "def graph_difference_std (dif_mean, dif_std, n_temp, c_value):\n",
    "    fig, ax1 = plt.subplots(1,1, figsize=(10, 6))\n",
    "    differences = dif_mean\n",
    "    color_value = cm.viridis(c_value)\n",
    "\n",
    "    ax1.barh(np.arange(0,len(differences),1), differences, xerr = dif_std , color=color_value, edgecolor='black')\n",
    "    ax1.set_title(r'$\\Delta H$ for each couple with'+f'{n_temp} templates')\n",
    "    ax1.set_yticks(np.arange(0,len(differences),1))\n",
    "    ax1.set_yticklabels([f'{test_elements[k]}{test_elements[l]}' for k in range(len(test_elements)) for l in range(k+1, len(test_elements))])\n",
    "    #ax.tick_params(axis='x', rotation=90)\n",
    "    ax1.grid(axis='x', linestyle=':')\n",
    "    ax1.set_xlabel('Enthalpy difference (eV/atom)')\n",
    "    ax1.set_xlim(-1.5, 2)\n",
    "    cartella = f'./TemplateSets/{n_temp}/'\n",
    "    nome_file = f'Differeces_{n_temp}.png'\n",
    "    percorso_completo = os.path.join(cartella, nome_file)\n",
    "    fig.savefig(percorso_completo)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'ntemp_start' : 8,\n",
    "    'ntemp_end' : 9,\n",
    "\n",
    "    'comp' : 1,\n",
    "    'lev_gen' : 0.1,\n",
    "    'n_sets' : 10,\n",
    "    'n_template' : 21,\n",
    "\n",
    "    'id_set' : 1,\n",
    "    'lev_red' : 0.7,\n",
    "    'weight_formation_entalphy' : 1,\n",
    "    'weight_occurrence' : 1,\n",
    "    'weight_sg' : 0.001,\n",
    "\n",
    "    'n_pairs' : 28,\n",
    "}\n",
    "\n",
    "test_elements=['Be', 'B', 'N', 'Mg', 'O', 'Li', 'C', 'Na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "random.seed(time.time())\n",
    "std_output = sys.stdout\n",
    "create_directory('./TemplateSets')\n",
    "\n",
    "sys.stdout = open(f'./TemplateSets/Log_sets_{hyperparameters[\"n_sets\"]}', 'w')\n",
    "means = np.zeros(21)\n",
    "stds = np.zeros(21)\n",
    "dif_vec = np.zeros((hyperparameters['n_sets'],28))\n",
    "\n",
    "ntemp_studied = hyperparameters['ntemp_end'] - hyperparameters['ntemp_start']\n",
    "dif_mean = np.zeros((ntemp_studied, 28))\n",
    "dif_std = np.zeros((ntemp_studied,28))\n",
    "\n",
    "for i in range(hyperparameters['ntemp_start'],hyperparameters['ntemp_end']):\n",
    "    hyperparameters['n_template'] = i\n",
    "    errors = np.zeros(hyperparameters['n_sets'])\n",
    "\n",
    "    for k in range(hyperparameters['n_sets']):\n",
    "        template_set = generate_one_templateset(hyperparameters, test_elements)\n",
    "        create_directory(f'./TemplateSets/{template_set.num_template}')\n",
    "        template_set.print_file(f'./TemplateSets/{template_set.num_template}/TemplateSet_{k}')\n",
    "        \n",
    "        reduction_set = generate_one_pairset(template_set, hyperparameters, test_elements)\n",
    "\n",
    "        dif_vec[k]= np.array(reduction_set.error_single_composition(hyperparameters))\n",
    "        errors[k] = reduction_set.total_error(hyperparameters) \n",
    "    dif_mean[i-hyperparameters['ntemp_start']] = np.mean(dif_vec, axis=0)\n",
    "    dif_std[i-hyperparameters['ntemp_start']] = np.std(dif_vec, axis=0)\n",
    "\n",
    "    graph_difference_std(dif_mean[i-hyperparameters['ntemp_start']] , dif_std[i-hyperparameters['ntemp_start']] , i, (i-hyperparameters['ntemp_start'])/ntemp_studied )\n",
    "    means[i-hyperparameters['ntemp_start']] = np.mean(errors)\n",
    "    stds[i-hyperparameters['ntemp_start']] = np.std(errors)\n",
    "\n",
    "sys.stdout = std_output\n",
    "\n",
    "print(means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
