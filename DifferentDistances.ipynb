{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from template_csp.managetemp import generate_one_templateset, generate_one_pairset, graph_difference_std\n",
    "import json\n",
    "# LEVEHSTEIN DISTANCE\n",
    "# LEVEHSTEIN DISTANCE\n",
    "def levensthein_distance(a1,a2):\n",
    "    dist=0\n",
    "    a1 = a1.copy()\n",
    "    a2 = a2.copy()\n",
    "    sorted_idxA = np.argsort(a1[0])\n",
    "    sorted_idxB = np.argsort(a2[0])\n",
    "    a1[1] = a1[1][sorted_idxA]\n",
    "    a2[1] = a2[1][sorted_idxB]\n",
    "    a1[1] = a1[1].astype(int)\n",
    "    a2[1] = a2[1].astype(int)\n",
    "    for i in range(len(a1[1])):\n",
    "        if a1[1][i] != a2[1][i]:\n",
    "            dist+=1-float(i)/len(a1[1])\n",
    "    return dist / ((len(a1[0]) + 1 ) / 2)\n",
    "# DISTANZA SOLO ENTALPIE\n",
    "def dist1(a1,a2):\n",
    "    dist=0\n",
    "    for i in range(len(a1[0])):\n",
    "        dist += ((a1[0].min() - a1[0][i])/(a1[0].min() - a1[0].max()) - (a2[0].min() - a2[0][i])/(a2[0].min() - a2[0].max())) ** 2\n",
    "    return (dist/len(a1[0])) ** 0.5\n",
    "# DISTANZA ENTALPIE E ORDINE \n",
    "def dist2(a1,a2):\n",
    "    dist=0\n",
    "    a1 = a1.copy()\n",
    "    a2 = a2.copy()\n",
    "    sorted_idxA = np.argsort(a1[0])\n",
    "    sorted_idxB = np.argsort(a2[0])\n",
    "    a1[1] = a1[1][sorted_idxA]\n",
    "    a2[1] = a2[1][sorted_idxB]\n",
    "    for i in range(len(a1)):\n",
    "        if a1[1][i] != a2[1][i]:\n",
    "            dist+=(1-float(i)/len(a1[1])) * (    abs(a1[0, int(a1[1,i]) ] - a1[0, int(a2[1,i]) ])/ (a1[0].max() - a1[0].min())    +   abs(a2[0, int(a1[1,i]) ] - a2[0, int(a2[1,i]) ])/ (a2[0].max() - a2[0].min())   ) / 2\n",
    "    return dist / ((len(a1[0]) + 1 ) / 2)\n",
    "# DISTANZA ORDINE E PESO SULLO SHIFT\n",
    "def dist3 (a1, a2):\n",
    "    dist = 0\n",
    "    a1 = a1.copy()\n",
    "    a2 = a2.copy()\n",
    "    sorted_idxA = np.argsort(a1[0])\n",
    "    sorted_idxB = np.argsort(a2[0])\n",
    "    a1[1] = a1[1][sorted_idxA]\n",
    "    a2[1] = a2[1][sorted_idxB]\n",
    "    for i in range(len(a1)):\n",
    "        if a1[1][i] != a2[1][i]:\n",
    "            dist += (1-float(i)/len(a1[1])) * ( abs(i-np.where(a1[1] == a2[1][i])[0][0])/len(a1[1]) + abs(i - np.where(a2[1] == a1[1][i])[0][0] )/len(a2[1]) ) / 2\n",
    "    return dist / ((len(a1[0]) + 1 ) / 2)\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "test_elements=['Be', 'B', 'N', 'Mg', 'O', 'Li', 'C', 'Na', 'Si', 'S', 'Cl', 'F', 'P', 'H', 'Al']\n",
    "\n",
    "hyperparameters = {\n",
    "    'ntemp_start' : 1,\n",
    "    'ntemp_end' : 21,\n",
    "\n",
    "    'comp' : 1,\n",
    "    'lev_gen' : 0.8,\n",
    "    'lev_gen_initial' : 0.8,\n",
    "    'step' : 0.1,\n",
    "    'n_sets' : 10,\n",
    "    'n_template' : 1,\n",
    "\n",
    "    'id_set' : 1,\n",
    "    'lev_red' : 0.9,\n",
    "    'weight_formation_entalphy' : 1,\n",
    "    'weight_occurrence' : 1,\n",
    "    'weight_sg' : 0.001,\n",
    "\n",
    "    'n_pairs' : 105,    \n",
    "}\n",
    "random.seed(time.time())\n",
    "\n",
    "distances = [levensthein_distance, dist1, dist3, dist3]\n",
    "thresholds = [0.8, 0.25, 0.25, 0.25]\n",
    "steps = [0.1, 0.02 , 0.02, 0.02]\n",
    "\n",
    "for dist_function in distances:\n",
    "\n",
    "    hyperparameters['lev_gen_initial'] = thresholds[distances.index(dist_function)]\n",
    "    hyperparameters['lev_gen'] = thresholds[distances.index(dist_function)]\n",
    "    hyperparameters['step'] = steps[distances.index(dist_function)]\n",
    "    print(hyperparameters['step'])\n",
    "\n",
    "    n_possible_couples = 105\n",
    "\n",
    "    dir_temp = f'./DIFFERENT_DISTANCES/{dist_function.__name__}/'\n",
    "    create_directory(dir_temp)\n",
    "\n",
    "    import json\n",
    "    with open(dir_temp + 'params.json', 'w') as f:\n",
    "        json.dump(hyperparameters, f, indent=4)\n",
    "\n",
    "    # Range in cui varia il numero di template estratti\n",
    "    ntemp_studied = hyperparameters['ntemp_end'] - hyperparameters['ntemp_start']\n",
    "\n",
    "    # Vettori per i risultati globali\n",
    "    means = np.zeros(ntemp_studied)\n",
    "    stds = np.zeros(ntemp_studied)\n",
    "\n",
    "    for i in tqdm(range(hyperparameters['ntemp_start'],hyperparameters['ntemp_end'], 1)):\n",
    "\n",
    "        hyperparameters['n_template'] = i\n",
    "\n",
    "        # vettori per store di errore totale e numero di template rimanenti del singolo set\n",
    "        errors = np.zeros(hyperparameters['n_sets'])\n",
    "        \n",
    "        with open('log.txt','a') as fstdout:\n",
    "            fstdout.write('##################################################\\n')\n",
    "            fstdout.write(f'Generating template set with {i} templates\\n')\n",
    "            fstdout.write('##################################################\\n')\n",
    "\n",
    "        for k in range(hyperparameters['n_sets']):\n",
    "            # Reset delle variabili\n",
    "            hyperparameters['lev_gen'] = hyperparameters['lev_gen_initial']\n",
    "            hyperparameters['id_set'] = k\n",
    "\n",
    "            # Generazione del template set inziale\n",
    "            template_set = generate_one_templateset(hyperparameters, test_elements, dist_function)\n",
    "\n",
    "            # Salvataggio del template set su file\n",
    "            create_directory(dir_temp+f'{template_set.num_template}')\n",
    "            template_set.recap_tempset(dir_temp+f'{template_set.num_template}/TemplateSet_{k}')\n",
    "\n",
    "\n",
    "            # Salvataggio dei risultati per ogni set\n",
    "            errors[k] = template_set.err_before() \n",
    "\n",
    "        # Errore totale con deviazione standard\n",
    "        means[i-hyperparameters['ntemp_start']] = np.mean(errors)\n",
    "        stds[i-hyperparameters['ntemp_start']] = np.std(errors)\n",
    "\n",
    "        df_tot = pd.DataFrame({'Means': means, 'Stds': stds})\n",
    "\n",
    "        # Salvataggio dei risultati su file\n",
    "        df_tot.to_csv(dir_temp+f'TotalStatics.csv', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "comp =1\n",
    "gs_df = pd.read_csv(f'A{comp}B/relaxation/GroundStates.txt', index_col=0, sep=\",\", na_filter = False)\n",
    "df = pd.read_csv(f'A{comp}B/relaxation/RELAX_DATA', sep=\",\", index_col=0, na_filter = False)\n",
    "couples = df.index.to_list()\n",
    "\n",
    "gs_df = gs_df.loc[couples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "df = pd.read_csv(f'A{comp}B/relaxation/RELAX_DATA', sep=\",\", index_col=0, na_filter = False)\n",
    "templates = np.arange(len(df.columns.to_list()))\n",
    "\n",
    "combinations = list(combinations(templates, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "comp = 1\n",
    "\n",
    "df = pd.read_csv(f'A{comp}B/relaxation/RELAX_DATA', sep=\",\", index_col=0, na_filter = False)\n",
    "gs_df = pd.read_csv(f'A{comp}B/relaxation/GroundStates.txt', sep=\",\",  index_col=0, na_filter = False)\n",
    "numtemp = 5\n",
    "\n",
    "errors_of_temp = np.zeros((len(combinations)))\n",
    "entalpie = df.to_numpy()\n",
    "gs = gs_df.to_numpy()\n",
    "\n",
    "for idx_try, try1 in tqdm(enumerate(combinations)):\n",
    "    for idx_couple in range(len(gs)):\n",
    "        errors = [max(entalpie[idx_couple, idx_temp]-gs[idx_couple][0], 0) for idx_temp in try1]\n",
    "        errors_of_temp[idx_try] += (np.array(errors).min())\n",
    "    errors_of_temp[idx_try] = errors_of_temp[idx_try]/len(gs)\n",
    "        \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
